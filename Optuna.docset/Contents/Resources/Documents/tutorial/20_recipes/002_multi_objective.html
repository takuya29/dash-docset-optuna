
<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Multi-objective Optimization with Optuna — Optuna 4.3.0 documentation</title>
<link href="../../_static/pygments.css?v=03e43079" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/theme.css?v=e59714d7" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css?v=d0d4e556" rel="stylesheet" type="text/css"/>
<link href="../../_static/favicon.ico" rel="shortcut icon"/>
<script src="../../_static/jquery.js?v=5d32c60e"></script>
<script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=c2f1cc2e"></script>
<script src="../../_static/doctools.js?v=888ff710"></script>
<script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=a56c686a"></script>
<script src="../../_static/js/theme.js"></script>
<link href="../../genindex.html" rel="index" title="Index"/>
<link href="../../search.html" rel="search" title="Search"/>
</head>
<body class="wy-body-for-nav">
<div class="navbar">
<div class="navbar ml-auto">
<ul class="navbar-nav">
<li>
<a class="header_link" href="https://optuna.org/#key_features">Key Features</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#code_examples">Code Examples</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#installation">Installation</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#dashboard">Dashboard</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#hub">OptunaHub</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#blog">Blog</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#video">Videos</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#paper">Paper</a>
</li>
</ul>
</div>
</div>
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a href="../../index.html">
<img alt="Logo" class="logo" src="../../_static/optuna-logo.png"/>
</a>
<div role="search">
<form action="../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">FAQ</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../../index.html">Optuna</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<!-- This file is necessary to remove "Edit on Github" button from readthedocs by following https://docs.readthedocs.io/en/stable/guides/remove-edit-buttons.html#remove-links-from-top-right-corner --><div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../../index.html"></a></li>
<li class="breadcrumb-item active">Multi-objective Optimization with Optuna</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-tutorial-20-recipes-002-multi-objective-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="multi-objective-optimization-with-optuna">
<a class="dashAnchor" name="//apple_ref/cpp/Section/Multi-objective Optimization with Optuna"></a><span id="multi-objective"></span><a class="dashAnchor" name="//apple_ref/cpp/Section/Multi-objective Optimization with Optuna"></a><span id="sphx-glr-tutorial-20-recipes-002-multi-objective-py"></span><h1>Multi-objective Optimization with Optuna<a class="headerlink" href="#multi-objective-optimization-with-optuna" title="Permalink to this heading"></a></h1>
<p>This tutorial showcases Optuna’s multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.</p>
<p>We use <a class="reference external" href="https://github.com/facebookresearch/fvcore">fvcore</a> to measure FLOPS.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fvcore.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlopCountAnalysis</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">optuna</span>


<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span> <span class="k">if</span> <a class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str"><span class="n">DIR</span></a> <span class="o">=</span> <span class="s2">".."</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a> <span class="o">=</span> <span class="mi">128</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_TRAIN_EXAMPLES</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a> <span class="o">*</span> <span class="mi">30</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_VALID_EXAMPLES</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a> <span class="o">*</span> <span class="mi">10</span>


<span class="k">def</span><span class="w"> </span><span class="nf">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">"n_layers"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">in_features</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">"n_units_l</span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">())</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">"dropout_</span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="n">p</span><span class="p">))</span>

        <span class="n">in_features</span> <span class="o">=</span> <span class="n">out_features</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" title="torch.nn.LogSoftmax"><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span></a><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>


<span class="c1"># Defines training and evaluation.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html#torch.nn.functional.nll_loss" title="torch.nn.functional.nll_loss"><span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span></a><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_VALID_EXAMPLES</span></a>

    <span class="n">flops</span> <span class="o">=</span> <span class="n">FlopCountAnalysis</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">),))</span><span class="o">.</span><span class="n">total</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<p>Define multi-objective objective function.
Objectives are FLOPS and accuracy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str"><span class="n">DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span></a><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_TRAIN_EXAMPLES</span></a><span class="p">))),</span>
        <span class="n">batch_size</span><span class="o">=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">val_dataset</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str"><span class="n">DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span></a><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_VALID_EXAMPLES</span></a><span class="p">))),</span>
        <span class="n">batch_size</span><span class="o">=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
    <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<section id="run-multi-objective-optimization">
<h2>Run multi-objective optimization<a class="headerlink" href="#run-multi-objective-optimization" title="Permalink to this heading"></a></h2>
<p>If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set <code class="docutils literal notranslate"><span class="pre">directions</span></code> to <code class="docutils literal notranslate"><span class="pre">["minimize",</span> <span class="pre">"maximize"]</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">directions</span><span class="o">=</span><span class="p">[</span><span class="s2">"minimize"</span><span class="p">,</span> <span class="s2">"maximize"</span><span class="p">])</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Number of finished trials: "</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">trials</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Number of finished trials:  30
</pre></div>
</div>
<p>Note that the following sections requires the installation of <a class="reference external" href="https://plotly.com/python">Plotly</a> for visualization
and <a class="reference external" href="https://scikit-learn.org/stable">scikit-learn</a> for hyperparameter importance calculation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>plotly
<span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>scikit-learn
<span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>nbformat<span class="w">  </span><span class="c1"># Required if you are running this tutorial in Jupyter Notebook.</span>
</pre></div>
</div>
<p>Check trials on Pareto front visually.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_pareto_front</span><span class="p">(</span><span class="n">study</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"FLOPS"</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">])</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div> <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
<script charset="utf-8" src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script> <div class="plotly-graph-div" id="8409f3e7-6be9-451a-9a97-53005e6d9c6b" style="height:100%; width:100%;"></div> <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("8409f3e7-6be9-451a-9a97-53005e6d9c6b")) {                    Plotly.newPlot(                        "8409f3e7-6be9-451a-9a97-53005e6d9c6b",                        [{"hovertemplate":"%{text}\u003cextra\u003eTrial\u003c\u002fextra\u003e","marker":{"color":[0,1,5,6,7,8,9,10,11,12,13,14,15,16,18,19,20,21,22,23,24,25,26,27,29],"colorbar":{"title":{"text":"Trial"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 0,\u003cbr\u003e  \"values\": [\u003cbr\u003e    48434.0,\u003cbr\u003e    0.66328125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 61,\u003cbr\u003e    \"dropout_0\": 0.4238497136511956,\u003cbr\u003e    \"lr\": 0.00010364496424761686\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 1,\u003cbr\u003e  \"values\": [\u003cbr\u003e    48909.0,\u003cbr\u003e    0.7765625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 57,\u003cbr\u003e    \"dropout_0\": 0.39163344870215167,\u003cbr\u003e    \"n_units_l1\": 63,\u003cbr\u003e    \"dropout_1\": 0.3282846180524406,\u003cbr\u003e    \"lr\": 0.020889586599019117\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 5,\u003cbr\u003e  \"values\": [\u003cbr\u003e    71190.0,\u003cbr\u003e    0.5203125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 79,\u003cbr\u003e    \"dropout_0\": 0.2663002511607926,\u003cbr\u003e    \"n_units_l1\": 71,\u003cbr\u003e    \"dropout_1\": 0.20232697803832078,\u003cbr\u003e    \"n_units_l2\": 45,\u003cbr\u003e    \"dropout_2\": 0.4351420565424938,\u003cbr\u003e    \"lr\": 6.058139786534737e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 6,\u003cbr\u003e  \"values\": [\u003cbr\u003e    49295.0,\u003cbr\u003e    0.7625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 55,\u003cbr\u003e    \"dropout_0\": 0.25975760225160965,\u003cbr\u003e    \"n_units_l1\": 95,\u003cbr\u003e    \"dropout_1\": 0.39527976591735847,\u003cbr\u003e    \"lr\": 0.00048810072679862686\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 7,\u003cbr\u003e  \"values\": [\u003cbr\u003e    45521.0,\u003cbr\u003e    0.6671875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 53,\u003cbr\u003e    \"dropout_0\": 0.3441191811647849,\u003cbr\u003e    \"n_units_l1\": 63,\u003cbr\u003e    \"dropout_1\": 0.3995680429590427,\u003cbr\u003e    \"lr\": 0.00023486294462765424\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 8,\u003cbr\u003e  \"values\": [\u003cbr\u003e    57203.0,\u003cbr\u003e    0.78671875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 63,\u003cbr\u003e    \"dropout_0\": 0.23310102082675746,\u003cbr\u003e    \"n_units_l1\": 107,\u003cbr\u003e    \"dropout_1\": 0.4620083196129172,\u003cbr\u003e    \"lr\": 0.017658656115079004\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 9,\u003cbr\u003e  \"values\": [\u003cbr\u003e    27558.0,\u003cbr\u003e    0.740625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 19,\u003cbr\u003e    \"dropout_0\": 0.27513630142863976,\u003cbr\u003e    \"n_units_l1\": 98,\u003cbr\u003e    \"dropout_1\": 0.4651849660596941,\u003cbr\u003e    \"n_units_l2\": 100,\u003cbr\u003e    \"dropout_2\": 0.31672928455511196,\u003cbr\u003e    \"lr\": 0.0008906596034868999\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 10,\u003cbr\u003e  \"values\": [\u003cbr\u003e    53198.0,\u003cbr\u003e    0.82734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 67,\u003cbr\u003e    \"dropout_0\": 0.20203457613957024,\u003cbr\u003e    \"lr\": 0.019955879212886447\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 11,\u003cbr\u003e  \"values\": [\u003cbr\u003e    57948.0,\u003cbr\u003e    0.76015625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 62,\u003cbr\u003e    \"dropout_0\": 0.36479920209485317,\u003cbr\u003e    \"n_units_l1\": 73,\u003cbr\u003e    \"dropout_1\": 0.40830250233044757,\u003cbr\u003e    \"n_units_l2\": 58,\u003cbr\u003e    \"dropout_2\": 0.4122569562828287,\u003cbr\u003e    \"lr\": 0.002945430201149406\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 12,\u003cbr\u003e  \"values\": [\u003cbr\u003e    69872.0,\u003cbr\u003e    0.6625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 88,\u003cbr\u003e    \"dropout_0\": 0.33863701091322856,\u003cbr\u003e    \"lr\": 6.821715258360572e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 13,\u003cbr\u003e  \"values\": [\u003cbr\u003e    110596.0,\u003cbr\u003e    0.71328125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 128,\u003cbr\u003e    \"dropout_0\": 0.4701047596594506,\u003cbr\u003e    \"n_units_l1\": 57,\u003cbr\u003e    \"dropout_1\": 0.4240705032619828,\u003cbr\u003e    \"n_units_l2\": 44,\u003cbr\u003e    \"dropout_2\": 0.25626184787816575,\u003cbr\u003e    \"lr\": 0.00044510045167750234\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 14,\u003cbr\u003e  \"values\": [\u003cbr\u003e    66128.0,\u003cbr\u003e    0.3234375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 82,\u003cbr\u003e    \"dropout_0\": 0.39409760961901275,\u003cbr\u003e    \"n_units_l1\": 20,\u003cbr\u003e    \"dropout_1\": 0.3332144984076185,\u003cbr\u003e    \"lr\": 1.2380418271426916e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 15,\u003cbr\u003e  \"values\": [\u003cbr\u003e    43160.0,\u003cbr\u003e    0.51328125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 50,\u003cbr\u003e    \"dropout_0\": 0.4676189426244408,\u003cbr\u003e    \"n_units_l1\": 66,\u003cbr\u003e    \"dropout_1\": 0.3094370935272527,\u003cbr\u003e    \"lr\": 7.168584674581062e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 16,\u003cbr\u003e  \"values\": [\u003cbr\u003e    36330.0,\u003cbr\u003e    0.27421875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 42,\u003cbr\u003e    \"dropout_0\": 0.4722785087238103,\u003cbr\u003e    \"n_units_l1\": 29,\u003cbr\u003e    \"dropout_1\": 0.3841519984032428,\u003cbr\u003e    \"n_units_l2\": 56,\u003cbr\u003e    \"dropout_2\": 0.20571492314154244,\u003cbr\u003e    \"lr\": 1.390414436421556e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 18,\u003cbr\u003e  \"values\": [\u003cbr\u003e    73696.0,\u003cbr\u003e    0.75234375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 88,\u003cbr\u003e    \"dropout_0\": 0.441413286109856,\u003cbr\u003e    \"n_units_l1\": 48,\u003cbr\u003e    \"dropout_1\": 0.44722544345444337,\u003cbr\u003e    \"lr\": 0.0004915065046539287\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 19,\u003cbr\u003e  \"values\": [\u003cbr\u003e    43726.0,\u003cbr\u003e    0.809375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 49,\u003cbr\u003e    \"dropout_0\": 0.31213082997618813,\u003cbr\u003e    \"n_units_l1\": 90,\u003cbr\u003e    \"dropout_1\": 0.463684204300947,\u003cbr\u003e    \"lr\": 0.0032128549143684796\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 20,\u003cbr\u003e  \"values\": [\u003cbr\u003e    88928.0,\u003cbr\u003e    0.81875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 112,\u003cbr\u003e    \"dropout_0\": 0.32438793520568393,\u003cbr\u003e    \"lr\": 0.0011093785552966533\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 21,\u003cbr\u003e  \"values\": [\u003cbr\u003e    42468.0,\u003cbr\u003e    0.5328125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 45,\u003cbr\u003e    \"dropout_0\": 0.2667604185732593,\u003cbr\u003e    \"n_units_l1\": 57,\u003cbr\u003e    \"dropout_1\": 0.39250216190395826,\u003cbr\u003e    \"n_units_l2\": 69,\u003cbr\u003e    \"dropout_2\": 0.2690471827432573,\u003cbr\u003e    \"lr\": 8.520493158860524e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 22,\u003cbr\u003e  \"values\": [\u003cbr\u003e    79266.0,\u003cbr\u003e    0.67734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 84,\u003cbr\u003e    \"dropout_0\": 0.4670339678688546,\u003cbr\u003e    \"n_units_l1\": 115,\u003cbr\u003e    \"dropout_1\": 0.4061629607805036,\u003cbr\u003e    \"n_units_l2\": 30,\u003cbr\u003e    \"dropout_2\": 0.35139054168433803,\u003cbr\u003e    \"lr\": 0.026090849554193943\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 23,\u003cbr\u003e  \"values\": [\u003cbr\u003e    63900.0,\u003cbr\u003e    0.7984375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 75,\u003cbr\u003e    \"dropout_0\": 0.22849001943426536,\u003cbr\u003e    \"n_units_l1\": 60,\u003cbr\u003e    \"dropout_1\": 0.47293202668703477,\u003cbr\u003e    \"lr\": 0.014657893279880463\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 24,\u003cbr\u003e  \"values\": [\u003cbr\u003e    113753.0,\u003cbr\u003e    0.4609375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 115,\u003cbr\u003e    \"dropout_0\": 0.31720861148360324,\u003cbr\u003e    \"n_units_l1\": 99,\u003cbr\u003e    \"dropout_1\": 0.3091498256287663,\u003cbr\u003e    \"n_units_l2\": 112,\u003cbr\u003e    \"dropout_2\": 0.3887590160247162,\u003cbr\u003e    \"lr\": 2.398610392409927e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 25,\u003cbr\u003e  \"values\": [\u003cbr\u003e    86856.0,\u003cbr\u003e    0.703125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 99,\u003cbr\u003e    \"dropout_0\": 0.24941059170650498,\u003cbr\u003e    \"n_units_l1\": 83,\u003cbr\u003e    \"dropout_1\": 0.22264880036350457,\u003cbr\u003e    \"n_units_l2\": 11,\u003cbr\u003e    \"dropout_2\": 0.32180489027982345,\u003cbr\u003e    \"lr\": 0.00037698148286198117\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 26,\u003cbr\u003e  \"values\": [\u003cbr\u003e    44708.0,\u003cbr\u003e    0.60234375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 48,\u003cbr\u003e    \"dropout_0\": 0.3779220469017349,\u003cbr\u003e    \"n_units_l1\": 122,\u003cbr\u003e    \"dropout_1\": 0.4791879619800727,\u003cbr\u003e    \"lr\": 0.0280835320644707\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 27,\u003cbr\u003e  \"values\": [\u003cbr\u003e    65108.0,\u003cbr\u003e    0.659375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 82,\u003cbr\u003e    \"dropout_0\": 0.39022111932970793,\u003cbr\u003e    \"lr\": 5.930353454755407e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 29,\u003cbr\u003e  \"values\": [\u003cbr\u003e    41720.0,\u003cbr\u003e    0.53359375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 46,\u003cbr\u003e    \"dropout_0\": 0.43913588579637963,\u003cbr\u003e    \"n_units_l1\": 101,\u003cbr\u003e    \"dropout_1\": 0.2298248826624159,\u003cbr\u003e    \"lr\": 4.8823946633542e-05\u003cbr\u003e  }\u003cbr\u003e}"],"x":[48434.0,48909.0,71190.0,49295.0,45521.0,57203.0,27558.0,53198.0,57948.0,69872.0,110596.0,66128.0,43160.0,36330.0,73696.0,43726.0,88928.0,42468.0,79266.0,63900.0,113753.0,86856.0,44708.0,65108.0,41720.0],"y":[0.66328125,0.7765625,0.5203125,0.7625,0.6671875,0.78671875,0.740625,0.82734375,0.76015625,0.6625,0.71328125,0.3234375,0.51328125,0.27421875,0.75234375,0.809375,0.81875,0.5328125,0.67734375,0.7984375,0.4609375,0.703125,0.60234375,0.659375,0.53359375],"type":"scatter"},{"hovertemplate":"%{text}\u003cextra\u003eBest Trial\u003c\u002fextra\u003e","marker":{"color":[2,3,4,17,28],"colorbar":{"title":{"text":"Best Trial"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 2,\u003cbr\u003e  \"values\": [\u003cbr\u003e    31560.0,\u003cbr\u003e    0.77734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 34,\u003cbr\u003e    \"dropout_0\": 0.4183710969305057,\u003cbr\u003e    \"n_units_l1\": 66,\u003cbr\u003e    \"dropout_1\": 0.2346230747074221,\u003cbr\u003e    \"n_units_l2\": 35,\u003cbr\u003e    \"dropout_2\": 0.20490787267630564,\u003cbr\u003e    \"lr\": 0.009203071114404417\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 3,\u003cbr\u003e  \"values\": [\u003cbr\u003e    39700.0,\u003cbr\u003e    0.78046875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 50,\u003cbr\u003e    \"dropout_0\": 0.47097784067311455,\u003cbr\u003e    \"lr\": 0.023620486987690054\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 4,\u003cbr\u003e  \"values\": [\u003cbr\u003e    53198.0,\u003cbr\u003e    0.82890625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 67,\u003cbr\u003e    \"dropout_0\": 0.24762896121334246,\u003cbr\u003e    \"lr\": 0.0039580015731770155\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 17,\u003cbr\u003e  \"values\": [\u003cbr\u003e    12704.0,\u003cbr\u003e    0.74765625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 16,\u003cbr\u003e    \"dropout_0\": 0.22793099906831185,\u003cbr\u003e    \"lr\": 0.000564595201298425\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 28,\u003cbr\u003e  \"values\": [\u003cbr\u003e    40494.0,\u003cbr\u003e    0.8265625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 51,\u003cbr\u003e    \"dropout_0\": 0.37198718706263145,\u003cbr\u003e    \"lr\": 0.0019012097871295994\u003cbr\u003e  }\u003cbr\u003e}"],"x":[31560.0,39700.0,53198.0,12704.0,40494.0],"y":[0.77734375,0.78046875,0.82890625,0.74765625,0.8265625],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };            </script> </div>
</div>
<br/>
<br/><p>Fetch the list of trials on the Pareto front with <a class="reference internal" href="../../reference/generated/optuna.study.Study.html#optuna.study.Study.best_trials" title="optuna.study.Study.best_trials"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_trials</span></code></a>.</p>
<p>For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of trials on the Pareto front: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">trial_with_highest_accuracy</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Trial with highest accuracy: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2">number: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2">params: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">params</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2">values: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">values</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Number of trials on the Pareto front: 5
Trial with highest accuracy:
        number: 4
        params: {'n_layers': 1, 'n_units_l0': 67, 'dropout_0': 0.24762896121334246, 'lr': 0.0039580015731770155}
        values: [53198.0, 0.82890625]
</pre></div>
</div>
<p>Learn which hyperparameters are affecting the flops most with hyperparameter importance.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_param_importances</span><span class="p">(</span>
    <span class="n">study</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target_name</span><span class="o">=</span><span class="s2">"flops"</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div> <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
<script charset="utf-8" src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script> <div class="plotly-graph-div" id="f84eab8e-c2a4-4b88-979e-a9619787a83b" style="height:100%; width:100%;"></div> <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("f84eab8e-c2a4-4b88-979e-a9619787a83b")) {                    Plotly.newPlot(                        "f84eab8e-c2a4-4b88-979e-a9619787a83b",                        [{"cliponaxis":false,"hovertemplate":["lr (FloatDistribution): 0.00023271057292998805\u003cextra\u003e\u003c\u002fextra\u003e","n_layers (IntDistribution): 0.0027465803745823723\u003cextra\u003e\u003c\u002fextra\u003e","dropout_0 (FloatDistribution): 0.007218210703768304\u003cextra\u003e\u003c\u002fextra\u003e","n_units_l0 (IntDistribution): 0.9898024983487193\u003cextra\u003e\u003c\u002fextra\u003e"],"name":"flops","orientation":"h","text":["\u003c0.01","\u003c0.01","\u003c0.01","0.99"],"textposition":"outside","x":[0.00023271057292998805,0.0027465803745823723,0.007218210703768304,0.9898024983487193],"y":["lr","n_layers","dropout_0","n_units_l0"],"type":"bar"}],                        {"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Hyperparameter Importance"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };            </script> </div>
</div>
<br/>
<br/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (2 minutes 1.089 seconds)</p>
<a class="dashAnchor" name="//apple_ref/cpp/Section/sphx_glr_download_tutorial_20_recipes_002_multi_objective.py"></a><div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorial-20-recipes-002-multi-objective-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a4ea522762978cb29312e091bc523c7a/002_multi_objective.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">002_multi_objective.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/82aa5c7e2a8d8749f9f6f65a6172eb9f/002_multi_objective.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">002_multi_objective.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4bf0db05e53701be6edd2d2db48ab6db/002_multi_objective.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">002_multi_objective.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</div>
</div>
<footer>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, Optuna Contributors.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
    <a href="../../privacy.html">Privacy Policy</a>.
     


</footer>
</div>
</div>
</section>
</div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>