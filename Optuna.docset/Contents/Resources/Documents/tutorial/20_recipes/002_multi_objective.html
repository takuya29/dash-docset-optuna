
<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Multi-objective Optimization with Optuna — Optuna 4.1.0 documentation</title>
<link href="../../_static/pygments.css?v=fa44fd50" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/theme.css?v=e59714d7" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css?v=d0d4e556" rel="stylesheet" type="text/css"/>
<link href="../../_static/favicon.ico" rel="shortcut icon"/>
<script src="../../_static/jquery.js?v=5d32c60e"></script>
<script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=0b6e6ca6"></script>
<script src="../../_static/doctools.js?v=888ff710"></script>
<script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=a56c686a"></script>
<script src="../../_static/js/theme.js"></script>
<link href="../../genindex.html" rel="index" title="Index"/>
<link href="../../search.html" rel="search" title="Search"/>
</head>
<body class="wy-body-for-nav">
<div class="navbar">
<div class="navbar ml-auto">
<ul class="navbar-nav">
<li>
<a class="header_link" href="https://optuna.org/#key_features">Key Features</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#code_examples">Code Examples</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#installation">Installation</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#dashboard">Dashboard</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#hub">OptunaHub</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#blog">Blog</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#video">Videos</a>
</li>
<li>
<a class="header_link" href="https://optuna.org/#paper">Paper</a>
</li>
</ul>
</div>
</div>
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a href="../../index.html">
<img alt="Logo" class="logo" src="../../_static/optuna-logo.png"/>
</a>
<div role="search">
<form action="../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">FAQ</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../../index.html">Optuna</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<!-- This file is necessary to remove "Edit on Github" button from readthedocs by following https://docs.readthedocs.io/en/stable/guides/remove-edit-buttons.html#remove-links-from-top-right-corner --><div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../../index.html"></a></li>
<li class="breadcrumb-item active">Multi-objective Optimization with Optuna</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-tutorial-20-recipes-002-multi-objective-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="multi-objective-optimization-with-optuna">
<a class="dashAnchor" name="//apple_ref/cpp/Section/Multi-objective Optimization with Optuna"></a><span id="multi-objective"></span><a class="dashAnchor" name="//apple_ref/cpp/Section/Multi-objective Optimization with Optuna"></a><span id="sphx-glr-tutorial-20-recipes-002-multi-objective-py"></span><h1>Multi-objective Optimization with Optuna<a class="headerlink" href="#multi-objective-optimization-with-optuna" title="Permalink to this heading"></a></h1>
<p>This tutorial showcases Optuna’s multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.</p>
<p>We use <a class="reference external" href="https://github.com/facebookresearch/fvcore">fvcore</a> to measure FLOPS.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">fvcore.nn</span> <span class="kn">import</span> <span class="n">FlopCountAnalysis</span>

<span class="kn">import</span> <span class="nn">optuna</span>


<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span> <span class="k">if</span> <a class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str"><span class="n">DIR</span></a> <span class="o">=</span> <span class="s2">".."</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a> <span class="o">=</span> <span class="mi">128</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_TRAIN_EXAMPLES</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a> <span class="o">*</span> <span class="mi">30</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_VALID_EXAMPLES</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a> <span class="o">*</span> <span class="mi">10</span>


<span class="k">def</span> <span class="nf">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">"n_layers"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">in_features</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">"n_units_l</span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">())</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">"dropout_</span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="n">p</span><span class="p">))</span>

        <span class="n">in_features</span> <span class="o">=</span> <span class="n">out_features</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" title="torch.nn.LogSoftmax"><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span></a><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>


<span class="c1"># Defines training and evaluation.</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html#torch.nn.functional.nll_loss" title="torch.nn.functional.nll_loss"><span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span></a><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_VALID_EXAMPLES</span></a>

    <span class="n">flops</span> <span class="o">=</span> <span class="n">FlopCountAnalysis</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">),))</span><span class="o">.</span><span class="n">total</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<p>Define multi-objective objective function.
Objectives are FLOPS and accuracy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str"><span class="n">DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span></a><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_TRAIN_EXAMPLES</span></a><span class="p">))),</span>
        <span class="n">batch_size</span><span class="o">=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">val_dataset</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str"><span class="n">DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span></a><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">N_VALID_EXAMPLES</span></a><span class="p">))),</span>
        <span class="n">batch_size</span><span class="o">=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.python.org/3/library/functions.html#int" title="builtins.int"><span class="n">BATCHSIZE</span></a><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">define_model</span><span class="p">(</span><span class="n">trial</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">DEVICE</span></a><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
    <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">flops</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<section id="run-multi-objective-optimization">
<h2>Run multi-objective optimization<a class="headerlink" href="#run-multi-objective-optimization" title="Permalink to this heading"></a></h2>
<p>If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set <code class="docutils literal notranslate"><span class="pre">directions</span></code> to <code class="docutils literal notranslate"><span class="pre">["minimize",</span> <span class="pre">"maximize"]</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">directions</span><span class="o">=</span><span class="p">[</span><span class="s2">"minimize"</span><span class="p">,</span> <span class="s2">"maximize"</span><span class="p">])</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Number of finished trials: "</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">trials</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Number of finished trials:  30
</pre></div>
</div>
<p>Note that the following sections requires the installation of <a class="reference external" href="https://plotly.com/python">Plotly</a> for visualization
and <a class="reference external" href="https://scikit-learn.org/stable">scikit-learn</a> for hyperparameter importance calculation:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>plotly
<span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>scikit-learn
<span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>nbformat<span class="w">  </span><span class="c1"># Required if you are running this tutorial in Jupyter Notebook.</span>
</pre></div>
</div>
<p>Check trials on Pareto front visually.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_pareto_front</span><span class="p">(</span><span class="n">study</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"FLOPS"</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">])</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div> <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
<script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script> <div class="plotly-graph-div" id="ea013b17-7b5a-4188-8b23-ef9be547e7aa" style="height:100%; width:100%;"></div> <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("ea013b17-7b5a-4188-8b23-ef9be547e7aa")) {                    Plotly.newPlot(                        "ea013b17-7b5a-4188-8b23-ef9be547e7aa",                        [{"hovertemplate":"%{text}\u003cextra\u003eTrial\u003c\u002fextra\u003e","marker":{"color":[0,1,2,3,4,5,7,8,10,11,12,13,14,15,16,17,18,19,20,21,23,25,26,28,29],"colorbar":{"title":{"text":"Trial"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 0,\u003cbr\u003e  \"values\": [\u003cbr\u003e    77018.0,\u003cbr\u003e    0.57109375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 97,\u003cbr\u003e    \"dropout_0\": 0.2956692397072882,\u003cbr\u003e    \"lr\": 1.4665211681375295e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 1,\u003cbr\u003e  \"values\": [\u003cbr\u003e    46832.0,\u003cbr\u003e    0.7765625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 58,\u003cbr\u003e    \"dropout_0\": 0.4111667485539252,\u003cbr\u003e    \"n_units_l1\": 20,\u003cbr\u003e    \"dropout_1\": 0.2641361687545828,\u003cbr\u003e    \"lr\": 0.0013808499692828653\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 2,\u003cbr\u003e  \"values\": [\u003cbr\u003e    68720.0,\u003cbr\u003e    0.409375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 78,\u003cbr\u003e    \"dropout_0\": 0.2331897220163853,\u003cbr\u003e    \"n_units_l1\": 86,\u003cbr\u003e    \"dropout_1\": 0.2882089165192042,\u003cbr\u003e    \"lr\": 1.4428052458634855e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 3,\u003cbr\u003e  \"values\": [\u003cbr\u003e    62208.0,\u003cbr\u003e    0.5671875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 78,\u003cbr\u003e    \"dropout_0\": 0.22564828864885067,\u003cbr\u003e    \"n_units_l1\": 12,\u003cbr\u003e    \"dropout_1\": 0.43441812816457853,\u003cbr\u003e    \"lr\": 0.035249410318719164\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 4,\u003cbr\u003e  \"values\": [\u003cbr\u003e    74636.0,\u003cbr\u003e    0.65625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 94,\u003cbr\u003e    \"dropout_0\": 0.43963706169163425,\u003cbr\u003e    \"lr\": 7.08651640056583e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 5,\u003cbr\u003e  \"values\": [\u003cbr\u003e    60344.0,\u003cbr\u003e    0.834375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 76,\u003cbr\u003e    \"dropout_0\": 0.45284767376043555,\u003cbr\u003e    \"lr\": 0.00333364176053962\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 7,\u003cbr\u003e  \"values\": [\u003cbr\u003e    12700.0,\u003cbr\u003e    0.09453125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 16,\u003cbr\u003e    \"dropout_0\": 0.3741426990064648,\u003cbr\u003e    \"n_units_l1\": 6,\u003cbr\u003e    \"dropout_1\": 0.43925815949646796,\u003cbr\u003e    \"lr\": 0.05846266954339092\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 8,\u003cbr\u003e  \"values\": [\u003cbr\u003e    108427.0,\u003cbr\u003e    0.60625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 121,\u003cbr\u003e    \"dropout_0\": 0.2378357367959553,\u003cbr\u003e    \"n_units_l1\": 69,\u003cbr\u003e    \"dropout_1\": 0.3139628687556625,\u003cbr\u003e    \"n_units_l2\": 66,\u003cbr\u003e    \"dropout_2\": 0.2724002505219311,\u003cbr\u003e    \"lr\": 7.704927673724843e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 10,\u003cbr\u003e  \"values\": [\u003cbr\u003e    77018.0,\u003cbr\u003e    0.65703125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 97,\u003cbr\u003e    \"dropout_0\": 0.39638142365948614,\u003cbr\u003e    \"lr\": 4.811424766124711e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 11,\u003cbr\u003e  \"values\": [\u003cbr\u003e    13498.0,\u003cbr\u003e    0.55859375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 17,\u003cbr\u003e    \"dropout_0\": 0.382049222882887,\u003cbr\u003e    \"lr\": 0.00010160319515035964\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 12,\u003cbr\u003e  \"values\": [\u003cbr\u003e    67850.0,\u003cbr\u003e    0.80078125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 80,\u003cbr\u003e    \"dropout_0\": 0.4681886651900037,\u003cbr\u003e    \"n_units_l1\": 57,\u003cbr\u003e    \"dropout_1\": 0.4682335651124277,\u003cbr\u003e    \"lr\": 0.002144724849560391\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 13,\u003cbr\u003e  \"values\": [\u003cbr\u003e    78441.0,\u003cbr\u003e    0.8046875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 91,\u003cbr\u003e    \"dropout_0\": 0.3705341335974446,\u003cbr\u003e    \"n_units_l1\": 41,\u003cbr\u003e    \"dropout_1\": 0.2098706201652281,\u003cbr\u003e    \"n_units_l2\": 66,\u003cbr\u003e    \"dropout_2\": 0.26077967404314195,\u003cbr\u003e    \"lr\": 0.0015938007429618073\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 14,\u003cbr\u003e  \"values\": [\u003cbr\u003e    101814.0,\u003cbr\u003e    0.21328125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 121,\u003cbr\u003e    \"dropout_0\": 0.45559303061092293,\u003cbr\u003e    \"n_units_l1\": 50,\u003cbr\u003e    \"dropout_1\": 0.4182103199705761,\u003cbr\u003e    \"n_units_l2\": 15,\u003cbr\u003e    \"dropout_2\": 0.4326938514655428,\u003cbr\u003e    \"lr\": 1.823949616791524e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 15,\u003cbr\u003e  \"values\": [\u003cbr\u003e    50816.0,\u003cbr\u003e    0.56484375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 64,\u003cbr\u003e    \"dropout_0\": 0.2894777618167153,\u003cbr\u003e    \"lr\": 0.07562140056646025\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 16,\u003cbr\u003e  \"values\": [\u003cbr\u003e    97370.0,\u003cbr\u003e    0.79765625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 116,\u003cbr\u003e    \"dropout_0\": 0.3526698024723246,\u003cbr\u003e    \"n_units_l1\": 51,\u003cbr\u003e    \"dropout_1\": 0.30317234204265536,\u003cbr\u003e    \"lr\": 0.0008812071628425541\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 17,\u003cbr\u003e  \"values\": [\u003cbr\u003e    82303.0,\u003cbr\u003e    0.81640625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 99,\u003cbr\u003e    \"dropout_0\": 0.3734287652986241,\u003cbr\u003e    \"n_units_l1\": 43,\u003cbr\u003e    \"dropout_1\": 0.47784060202043344,\u003cbr\u003e    \"lr\": 0.0038392223902423213\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 18,\u003cbr\u003e  \"values\": [\u003cbr\u003e    24156.0,\u003cbr\u003e    0.696875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 26,\u003cbr\u003e    \"dropout_0\": 0.25196237775977354,\u003cbr\u003e    \"n_units_l1\": 62,\u003cbr\u003e    \"dropout_1\": 0.33362402836071137,\u003cbr\u003e    \"n_units_l2\": 30,\u003cbr\u003e    \"dropout_2\": 0.45108607068168083,\u003cbr\u003e    \"lr\": 0.0028180901316819575\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 19,\u003cbr\u003e  \"values\": [\u003cbr\u003e    68235.0,\u003cbr\u003e    0.61875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 75,\u003cbr\u003e    \"dropout_0\": 0.43361994055370356,\u003cbr\u003e    \"n_units_l1\": 111,\u003cbr\u003e    \"dropout_1\": 0.23834988241428032,\u003cbr\u003e    \"lr\": 5.923898801728579e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 20,\u003cbr\u003e  \"values\": [\u003cbr\u003e    12704.0,\u003cbr\u003e    0.690625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 16,\u003cbr\u003e    \"dropout_0\": 0.22018706266196342,\u003cbr\u003e    \"lr\": 0.00042492285964109664\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 21,\u003cbr\u003e  \"values\": [\u003cbr\u003e    58756.0,\u003cbr\u003e    0.64453125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 74,\u003cbr\u003e    \"dropout_0\": 0.21095411440651682,\u003cbr\u003e    \"lr\": 5.6201228035766254e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 23,\u003cbr\u003e  \"values\": [\u003cbr\u003e    43960.0,\u003cbr\u003e    0.18359375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 45,\u003cbr\u003e    \"dropout_0\": 0.3014468293436898,\u003cbr\u003e    \"n_units_l1\": 73,\u003cbr\u003e    \"dropout_1\": 0.4418809719813278,\u003cbr\u003e    \"n_units_l2\": 65,\u003cbr\u003e    \"dropout_2\": 0.43341814992998506,\u003cbr\u003e    \"lr\": 1.986952114098959e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 25,\u003cbr\u003e  \"values\": [\u003cbr\u003e    66776.0,\u003cbr\u003e    0.37109375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 83,\u003cbr\u003e    \"dropout_0\": 0.46840441030790925,\u003cbr\u003e    \"n_units_l1\": 4,\u003cbr\u003e    \"dropout_1\": 0.4905489885090012,\u003cbr\u003e    \"n_units_l2\": 98,\u003cbr\u003e    \"dropout_2\": 0.29600344303476067,\u003cbr\u003e    \"lr\": 0.00021179005933464807\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 26,\u003cbr\u003e  \"values\": [\u003cbr\u003e    100838.0,\u003cbr\u003e    0.77421875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 127,\u003cbr\u003e    \"dropout_0\": 0.40208231483898216,\u003cbr\u003e    \"lr\": 0.0003260250188933905\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 28,\u003cbr\u003e  \"values\": [\u003cbr\u003e    83370.0,\u003cbr\u003e    0.8203125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 105,\u003cbr\u003e    \"dropout_0\": 0.27601983625390114,\u003cbr\u003e    \"lr\": 0.0010008148021776278\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 29,\u003cbr\u003e  \"values\": [\u003cbr\u003e    51610.0,\u003cbr\u003e    0.70625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 65,\u003cbr\u003e    \"dropout_0\": 0.41287898434222203,\u003cbr\u003e    \"lr\": 0.05262392155929193\u003cbr\u003e  }\u003cbr\u003e}"],"x":[77018.0,46832.0,68720.0,62208.0,74636.0,60344.0,12700.0,108427.0,77018.0,13498.0,67850.0,78441.0,101814.0,50816.0,97370.0,82303.0,24156.0,68235.0,12704.0,58756.0,43960.0,66776.0,100838.0,83370.0,51610.0],"y":[0.57109375,0.7765625,0.409375,0.5671875,0.65625,0.834375,0.09453125,0.60625,0.65703125,0.55859375,0.80078125,0.8046875,0.21328125,0.56484375,0.79765625,0.81640625,0.696875,0.61875,0.690625,0.64453125,0.18359375,0.37109375,0.77421875,0.8203125,0.70625],"type":"scatter"},{"hovertemplate":"%{text}\u003cextra\u003eBest Trial\u003c\u002fextra\u003e","marker":{"color":[6,9,22,24,27],"colorbar":{"title":{"text":"Best Trial"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 6,\u003cbr\u003e  \"values\": [\u003cbr\u003e    9882.0,\u003cbr\u003e    0.1015625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 10,\u003cbr\u003e    \"dropout_0\": 0.4399537558972296,\u003cbr\u003e    \"n_units_l1\": 8,\u003cbr\u003e    \"dropout_1\": 0.2554385111274616,\u003cbr\u003e    \"n_units_l2\": 109,\u003cbr\u003e    \"dropout_2\": 0.3788747251581489,\u003cbr\u003e    \"lr\": 0.05386448288550097\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 9,\u003cbr\u003e  \"values\": [\u003cbr\u003e    12704.0,\u003cbr\u003e    0.73125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 16,\u003cbr\u003e    \"dropout_0\": 0.4756276952247083,\u003cbr\u003e    \"lr\": 0.0018805751221179518\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 22,\u003cbr\u003e  \"values\": [\u003cbr\u003e    41288.0,\u003cbr\u003e    0.7953125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 52,\u003cbr\u003e    \"dropout_0\": 0.4872568219482489,\u003cbr\u003e    \"lr\": 0.0012930643844333372\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 24,\u003cbr\u003e  \"values\": [\u003cbr\u003e    56374.0,\u003cbr\u003e    0.8078125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 71,\u003cbr\u003e    \"dropout_0\": 0.25203169882547133,\u003cbr\u003e    \"lr\": 0.0037628837904527587\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 27,\u003cbr\u003e  \"values\": [\u003cbr\u003e    58756.0,\u003cbr\u003e    0.8359375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 74,\u003cbr\u003e    \"dropout_0\": 0.2395261304107999,\u003cbr\u003e    \"lr\": 0.0016024214944167243\u003cbr\u003e  }\u003cbr\u003e}"],"x":[9882.0,12704.0,41288.0,56374.0,58756.0],"y":[0.1015625,0.73125,0.7953125,0.8078125,0.8359375],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script> </div>
</div>
<br/>
<br/><p>Fetch the list of trials on the Pareto front with <a class="reference internal" href="../../reference/generated/optuna.study.Study.html#optuna.study.Study.best_trials" title="optuna.study.Study.best_trials"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_trials</span></code></a>.</p>
<p>For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of trials on the Pareto front: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">trial_with_highest_accuracy</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Trial with highest accuracy: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2">number: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2">params: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">params</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2">values: </span><span class="si">{</span><span class="n">trial_with_highest_accuracy</span><span class="o">.</span><span class="n">values</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Number of trials on the Pareto front: 5
Trial with highest accuracy:
        number: 27
        params: {'n_layers': 1, 'n_units_l0': 74, 'dropout_0': 0.2395261304107999, 'lr': 0.0016024214944167243}
        values: [58756.0, 0.8359375]
</pre></div>
</div>
<p>Learn which hyperparameters are affecting the flops most with hyperparameter importance.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_param_importances</span><span class="p">(</span>
    <span class="n">study</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target_name</span><span class="o">=</span><span class="s2">"flops"</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div> <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
<script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script> <div class="plotly-graph-div" id="65c2803c-67ec-461a-a0e8-e669bcf98585" style="height:100%; width:100%;"></div> <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("65c2803c-67ec-461a-a0e8-e669bcf98585")) {                    Plotly.newPlot(                        "65c2803c-67ec-461a-a0e8-e669bcf98585",                        [{"cliponaxis":false,"hovertemplate":["lr (FloatDistribution): 0.00024254446477938626\u003cextra\u003e\u003c\u002fextra\u003e","n_layers (IntDistribution): 0.0006161965829288624\u003cextra\u003e\u003c\u002fextra\u003e","dropout_0 (FloatDistribution): 0.002571152076273792\u003cextra\u003e\u003c\u002fextra\u003e","n_units_l0 (IntDistribution): 0.9965701068760179\u003cextra\u003e\u003c\u002fextra\u003e"],"name":"flops","orientation":"h","text":["\u003c0.01","\u003c0.01","\u003c0.01","1.00"],"textposition":"outside","x":[0.00024254446477938626,0.0006161965829288624,0.002571152076273792,0.9965701068760179],"y":["lr","n_layers","dropout_0","n_units_l0"],"type":"bar"}],                        {"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Hyperparameter Importance"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script> </div>
</div>
<br/>
<br/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (2 minutes 1.464 seconds)</p>
<a class="dashAnchor" name="//apple_ref/cpp/Section/sphx_glr_download_tutorial_20_recipes_002_multi_objective.py"></a><div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorial-20-recipes-002-multi-objective-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a4ea522762978cb29312e091bc523c7a/002_multi_objective.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">002_multi_objective.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/82aa5c7e2a8d8749f9f6f65a6172eb9f/002_multi_objective.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">002_multi_objective.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4bf0db05e53701be6edd2d2db48ab6db/002_multi_objective.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">002_multi_objective.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</div>
</div>
<footer>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, Optuna Contributors.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
    <a href="../../privacy.html">Privacy Policy</a>.
     


</footer>
</div>
</div>
</section>
</div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>