{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Early-stopping independent evaluations by Wilcoxon pruner\n\nThis tutorial showcases Optuna's :class:`~optuna.pruners.WilcoxonPruner`.\nThis pruner is effective for objective functions that averages multiple evaluations.\n\nWe solve [Traveling Salesman Problem (TSP)](https://en.wikipedia.org/w/index.php?title=Travelling_salesman_problem&oldid=1211575788)_\nby [Simulated Annealing (SA)](https://en.wikipedia.org/w/index.php?title=Simulated_annealing&oldid=1187355062)_.\n\n## Overview: Solving Traveling Salesman Problem with Simulated Annealing\n\nTraveling Salesman Problem (TSP) is a classic problem in combinatorial optimization\nthat involves finding the shortest possible route for a salesman\nwho needs to visit a set of cities, each exactly once, and return to the starting city.\nTSP has been extensively studied in fields such as mathematics, computer science,\nand operations research, and has numerous practical applications in logistics,\nmanufacturing, and DNA sequencing, among others.\nThe problem is classified as NP-hard, so approximation algorithms or\nheuristic methods are commonly employed for larger instances.\n\nOne simple heuristic method applicable to TSP is simulated annealing (SA).\nSA starts with an initial solution (it can be constructed by a simpler heuristic\nlike greedy method), and it randomly checks the neighborhood (defined later)\nof the solution. If a neighbor is better, the solution is updated to the neighbor.\nIf the neighbor is worse, SA still updates the solution to the neighbor with\nprobability $e^{-\\Delta c / T}$, where\n$\\Delta c (> 0)$ is the difference of\nthe cost (sum of the distance) between the new solution and the old one and\n$T$ is a parameter called \"temperature\". The temperature controls\nhow much worsening of the solution is tolerated to escape from the local minimum\n(high means more tolerant). If the temperature is too low, SA will quickly\nfall into a local minimum; if the temperature is too high, SA will be like\na random walk and the optimization will be inefficient. Typically, we set a\n\"temperature schedule\" that starts from a high temperature and gradually\ndecreases to zero.\n\nThere are several ways to define neighborhood for TSP, but we use a\nsimple neighborhood called [2-opt](https://en.wikipedia.org/w/index.php?title=2-opt&oldid=1194969927)_. 2-opt neighbor chooses a path in\nthe current solution and reverses the visiting order in the path.\nFor example, if the initial solution is `a\u2192b\u2192c\u2192d\u2192e\u2192a`, `a\u2192d\u2192c\u2192b\u2192e\u2192a` is\na 2-opt neighbor (the path from `b` to `d` is reversed).\nThis neighborhood is good because computing the difference of the cost\ncan be done in constant time (we only need to care about the start\nand the end of the chosen path).\n\n# Main Tutorial: Tuning SA Parameters for TSP\n\nFirst, let's import some packages and define the parameters setting of SA\nand the cost function of TSP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\nimport math\n\nimport numpy as np\nimport optuna\nimport plotly.graph_objects as go\nfrom numpy.linalg import norm\n\n\n@dataclass\nclass SAOptions:\n    max_iter: int = 10000\n    T0: float = 1.0\n    alpha: float = 2.0\n    patience: int = 50\n\n\ndef tsp_cost(vertices: np.ndarray, idxs: np.ndarray) -> float:\n    return norm(vertices[idxs] - vertices[np.roll(idxs, 1)], axis=-1).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Greedy solution for initial guess.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def tsp_greedy(vertices: np.ndarray) -> np.ndarray:\n    idxs = [0]\n    for _ in range(len(vertices) - 1):\n        dists_from_last = norm(vertices[idxs[-1], None] - vertices, axis=-1)\n        dists_from_last[idxs] = np.inf\n        idxs.append(np.argmin(dists_from_last))\n    return np.array(idxs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>For simplicity of implementation, we use SA with the 2-opt neighborhood to solve TSP,\n    but note that this is far from the \"best\" way to solve TSP. There are significantly more\n    advanced methods than this method.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The implementation of SA with 2-opt neighborhood is following.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def tsp_simulated_annealing(vertices: np.ndarray, options: SAOptions) -> np.ndarray:\n\n    def temperature(t: float):\n        assert 0.0 <= t and t <= 1.0\n        return options.T0 * (1 - t) ** options.alpha\n\n    N = len(vertices)\n\n    idxs = tsp_greedy(vertices)\n    cost = tsp_cost(vertices, idxs)\n    best_idxs = idxs.copy()\n    best_cost = cost\n    remaining_patience = options.patience\n\n    for iter in range(options.max_iter):\n\n        i = np.random.randint(0, N)\n        j = (i + 2 + np.random.randint(0, N - 3)) % N\n        i, j = min(i, j), max(i, j)\n        # Reverse the order of vertices between range [i+1, j].\n\n        # cost difference by 2-opt reversal\n        delta_cost = (\n            -norm(vertices[idxs[(i + 1) % N]] - vertices[idxs[i]])\n            - norm(vertices[idxs[j]] - vertices[idxs[(j + 1) % N]])\n            + norm(vertices[idxs[i]] - vertices[idxs[j]])\n            + norm(vertices[idxs[(i + 1) % N]] - vertices[idxs[(j + 1) % N]])\n        )\n        temp = temperature(iter / options.max_iter)\n        if delta_cost <= 0.0 or np.random.random() < math.exp(-delta_cost / temp):\n            # accept the 2-opt reversal\n            cost += delta_cost\n            idxs[i + 1 : j + 1] = idxs[i + 1 : j + 1][::-1]\n            if cost < best_cost:\n                best_idxs[:] = idxs\n                best_cost = cost\n                remaining_patience = options.patience\n\n        if cost > best_cost:\n            # If the best solution is not updated for \"patience\" iteratoins,\n            # restart from the best solution.\n            remaining_patience -= 1\n            if remaining_patience == 0:\n                idxs[:] = best_idxs\n                cost = best_cost\n                remaining_patience = options.patience\n\n    return best_idxs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We make a random dataset of TSP.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_dataset(num_vertex: int, num_problem: int, seed: int = 0) -> np.ndarray:\n    rng = np.random.default_rng(seed=seed)\n    return rng.random((num_problem, num_vertex, 2))\n\n\ndataset = make_dataset(\n    num_vertex=100,\n    num_problem=50,\n)\n\nN_TRIALS = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set a very small number of SA iterations for demonstration purpose.\nIn practice, you should set a larger number of iterations (e.g., 1000000).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N_SA_ITER = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We counts the number of evaluation to know how many problems is pruned.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_evaluation = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we optimize three parameters: ``T0``, ``alpha``, and ``patience``.\n\n## ``T0`` and ``alpha`` defining the temperature schedule\n\nIn simulated annealing, it is important to determine a good temperature scheduling, but\nthere is no \"silver schedule\" that is good for all problems, so we must tune the schedule\nfor this problem.\nThis code parametrizes the temperature as a monomial function ``T0 * (1 - t) ** alpha``, where\n`t` progresses from 0 to 1. We try to optimize the two parameters ``T0`` and ``alpha``.\n\n## ``patience``\n\nThis parameter specifies a threshold of how many iterations we allow the annealing process\ncontinue without updating the best value. Practically, simulated annealing often drives\nthe solution far away from the current best solution, and rolling back to the best solution\nperiodically often improves optimization efficiency a lot. However, if the rollback happens\ntoo often, the optimization may get stuck in a local optimum, so we must tune the threshold\nto a sensible amount.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Some samplers, including the default ``TPESampler``, currently cannot utilize the\n    information of pruned trials effectively (especially when the last intermediate value\n    is not the best approximation to the final objective function).\n    As a workaround for this issue, you can return an estimation of the final value\n    (e.g., the average of all evaluated values) when ``trial.should_prune()`` returns ``True``,\n    instead of `raise optuna.TrialPruned()`.\n    This will improve the sampler performance.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the objective function to be optimized as follows.\nWe early stop the evaluation by using the pruner.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n    global num_evaluation\n    options = SAOptions(\n        max_iter=N_SA_ITER,\n        T0=trial.suggest_float(\"T0\", 0.01, 10.0, log=True),\n        alpha=trial.suggest_float(\"alpha\", 1.0, 10.0, log=True),\n        patience=trial.suggest_int(\"patience\", 10, 1000, log=True),\n    )\n    results = []\n\n    # For best results, shuffle the evaluation order in each trial.\n    instance_ids = np.random.permutation(len(dataset))\n    for instance_id in instance_ids:\n        num_evaluation += 1\n        result_idxs = tsp_simulated_annealing(vertices=dataset[instance_id], options=options)\n        result_cost = tsp_cost(dataset[instance_id], result_idxs)\n        results.append(result_cost)\n\n        trial.report(result_cost, instance_id)\n        if trial.should_prune():\n            # Return the current predicted value instead of raising `TrialPruned`.\n            # This is a workaround to tell the Optuna about the evaluation\n            # results in pruned trials.\n            return sum(results) / len(results)\n\n    return sum(results) / len(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use ``TPESampler`` with ``WilcoxonPruner``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\nsampler = optuna.samplers.TPESampler(seed=1)\npruner = optuna.pruners.WilcoxonPruner(p_threshold=0.1)\nstudy = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\nstudy.enqueue_trial({\"T0\": 1.0, \"alpha\": 2.0, \"patience\": 50})  # default params\nstudy.optimize(objective, n_trials=N_TRIALS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can show the optimization results as:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The number of trials: {len(study.trials)}\")\nprint(f\"Best value: {study.best_value} (params: {study.best_params})\")\nprint(f\"Number of evaluation: {num_evaluation} / {len(dataset) * N_TRIALS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the optimization history.\nNote that this plot shows both completed and pruned trials in same ways.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the number of evaluations in each trial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_values = [x for x in range(len(study.trials)) if x != study.best_trial.number]\ny_values = [\n    len(t.intermediate_values) for t in study.trials if t.number != study.best_trial.number\n]\nbest_trial_y = [len(study.best_trial.intermediate_values)]\nbest_trial_x = [study.best_trial.number]\nfig = go.Figure()\nfig.add_trace(go.Bar(x=x_values, y=y_values, name=\"Evaluations\"))\nfig.add_trace(go.Bar(x=best_trial_x, y=best_trial_y, name=\"Best Trial\", marker_color=\"red\"))\nfig.update_layout(\n    title=\"Number of evaluations in each trial\",\n    xaxis_title=\"Trial number\",\n    yaxis_title=\"Number of evaluations before pruned\",\n)\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the greedy solution (used by initial guess) of a TSP problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "d = dataset[0]\nresult_idxs = tsp_greedy(d)\nresult_idxs = np.append(result_idxs, result_idxs[0])\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=d[result_idxs, 0], y=d[result_idxs, 1], mode=\"lines+markers\"))\nfig.update_layout(\n    title=f\"greedy solution (initial guess),  cost: {tsp_cost(d, result_idxs):.3f}\",\n    xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n)\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the solution found by ``tsp_simulated_annealing`` of the same TSP problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = study.best_params\noptions = SAOptions(\n    max_iter=N_SA_ITER,\n    patience=params[\"patience\"],\n    T0=params[\"T0\"],\n    alpha=params[\"alpha\"],\n)\nresult_idxs = tsp_simulated_annealing(d, options)\nresult_idxs = np.append(result_idxs, result_idxs[0])\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=d[result_idxs, 0], y=d[result_idxs, 1], mode=\"lines+markers\"))\nfig.update_layout(\n    title=f\"n_iter: {options.max_iter}, cost: {tsp_cost(d, result_idxs):.3f}\",\n    xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n)\nfig"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}