
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/20_recipes/002_multi_objective.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorial_20_recipes_002_multi_objective.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_20_recipes_002_multi_objective.py:


.. _multi_objective:

Multi-objective Optimization with Optuna
========================================

This tutorial showcases Optuna's multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.

We use `fvcore <https://github.com/facebookresearch/fvcore>`_ to measure FLOPS.

.. GENERATED FROM PYTHON SOURCE LINES 12-74

.. code-block:: Python


    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision
    from fvcore.nn import FlopCountAnalysis

    import optuna


    DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    DIR = ".."
    BATCHSIZE = 128
    N_TRAIN_EXAMPLES = BATCHSIZE * 30
    N_VALID_EXAMPLES = BATCHSIZE * 10


    def define_model(trial):
        n_layers = trial.suggest_int("n_layers", 1, 3)
        layers = []

        in_features = 28 * 28
        for i in range(n_layers):
            out_features = trial.suggest_int("n_units_l{}".format(i), 4, 128)
            layers.append(nn.Linear(in_features, out_features))
            layers.append(nn.ReLU())
            p = trial.suggest_float("dropout_{}".format(i), 0.2, 0.5)
            layers.append(nn.Dropout(p))

            in_features = out_features

        layers.append(nn.Linear(in_features, 10))
        layers.append(nn.LogSoftmax(dim=1))

        return nn.Sequential(*layers)


    # Defines training and evaluation.
    def train_model(model, optimizer, train_loader):
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
            optimizer.zero_grad()
            F.nll_loss(model(data), target).backward()
            optimizer.step()


    def eval_model(model, valid_loader):
        model.eval()
        correct = 0
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(valid_loader):
                data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
                pred = model(data).argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()

        accuracy = correct / N_VALID_EXAMPLES

        flops = FlopCountAnalysis(model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),)).total()
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 75-77

Define multi-objective objective function.
Objectives are FLOPS and accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 77-107

.. code-block:: Python

    def objective(trial):
        train_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=True, download=True, transform=torchvision.transforms.ToTensor()
        )
        train_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )

        val_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=False, transform=torchvision.transforms.ToTensor()
        )
        val_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )
        model = define_model(trial).to(DEVICE)

        optimizer = torch.optim.Adam(
            model.parameters(), trial.suggest_float("lr", 1e-5, 1e-1, log=True)
        )

        for epoch in range(10):
            train_model(model, optimizer, train_loader)
        flops, accuracy = eval_model(model, val_loader)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 108-115

Run multi-objective optimization
--------------------------------

If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set ``directions`` to ``["minimize", "maximize"]``.

.. GENERATED FROM PYTHON SOURCE LINES 115-121

.. code-block:: Python

    study = optuna.create_study(directions=["minimize", "maximize"])
    study.optimize(objective, n_trials=30, timeout=300)

    print("Number of finished trials: ", len(study.trials))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Number of finished trials:  30




.. GENERATED FROM PYTHON SOURCE LINES 122-123

Check trials on Pareto front visually.

.. GENERATED FROM PYTHON SOURCE LINES 123-126

.. code-block:: Python

    optuna.visualization.plot_pareto_front(study, target_names=["FLOPS", "accuracy"])







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.30.0.min.js"></script>                <div id="60e35e9d-453d-4eaa-b678-5931ff6efa4b" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("60e35e9d-453d-4eaa-b678-5931ff6efa4b")) {                    Plotly.newPlot(                        "60e35e9d-453d-4eaa-b678-5931ff6efa4b",                        [{"hovertemplate":"%{text}\u003cextra\u003eTrial\u003c\u002fextra\u003e","marker":{"color":[0,1,2,3,4,5,6,7,8,10,11,13,14,15,16,18,19,20,21,22,23,26,28,29],"colorbar":{"title":{"text":"Trial"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 0,\u003cbr\u003e  \"values\": [\u003cbr\u003e    27104.0,\u003cbr\u003e    0.684375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 15,\u003cbr\u003e    \"dropout_0\": 0.36626365766916025,\u003cbr\u003e    \"n_units_l1\": 112,\u003cbr\u003e    \"dropout_1\": 0.4792605351401343,\u003cbr\u003e    \"n_units_l2\": 112,\u003cbr\u003e    \"dropout_2\": 0.498709368977431,\u003cbr\u003e    \"lr\": 0.0005903216921240933\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 1,\u003cbr\u003e  \"values\": [\u003cbr\u003e    43631.0,\u003cbr\u003e    0.47109375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 53,\u003cbr\u003e    \"dropout_0\": 0.3222734525845403,\u003cbr\u003e    \"n_units_l1\": 33,\u003cbr\u003e    \"dropout_1\": 0.32592355186014177,\u003cbr\u003e    \"lr\": 2.7078037465826357e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 2,\u003cbr\u003e  \"values\": [\u003cbr\u003e    96074.0,\u003cbr\u003e    0.83203125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 121,\u003cbr\u003e    \"dropout_0\": 0.42529259470111824,\u003cbr\u003e    \"lr\": 0.0016983656678934104\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 3,\u003cbr\u003e  \"values\": [\u003cbr\u003e    49008.0,\u003cbr\u003e    0.7546875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 58,\u003cbr\u003e    \"dropout_0\": 0.36245986246433703,\u003cbr\u003e    \"n_units_l1\": 52,\u003cbr\u003e    \"dropout_1\": 0.3322920755249277,\u003cbr\u003e    \"lr\": 0.027414864112969055\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 4,\u003cbr\u003e  \"values\": [\u003cbr\u003e    45825.0,\u003cbr\u003e    0.09375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 52,\u003cbr\u003e    \"dropout_0\": 0.43277369633935825,\u003cbr\u003e    \"n_units_l1\": 29,\u003cbr\u003e    \"dropout_1\": 0.48774751497943025,\u003cbr\u003e    \"n_units_l2\": 91,\u003cbr\u003e    \"dropout_2\": 0.458922447940606,\u003cbr\u003e    \"lr\": 0.0882087978548004\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 5,\u003cbr\u003e  \"values\": [\u003cbr\u003e    74336.0,\u003cbr\u003e    0.66875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 86,\u003cbr\u003e    \"dropout_0\": 0.23134250955154584,\u003cbr\u003e    \"n_units_l1\": 72,\u003cbr\u003e    \"dropout_1\": 0.43654839322018746,\u003cbr\u003e    \"lr\": 0.03702726418088834\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 6,\u003cbr\u003e  \"values\": [\u003cbr\u003e    65117.0,\u003cbr\u003e    0.55078125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 73,\u003cbr\u003e    \"dropout_0\": 0.30809697614169035,\u003cbr\u003e    \"n_units_l1\": 95,\u003cbr\u003e    \"dropout_1\": 0.24787032212712065,\u003cbr\u003e    \"lr\": 3.345306142657119e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 7,\u003cbr\u003e  \"values\": [\u003cbr\u003e    88080.0,\u003cbr\u003e    0.37421875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 96,\u003cbr\u003e    \"dropout_0\": 0.24806807215180687,\u003cbr\u003e    \"n_units_l1\": 113,\u003cbr\u003e    \"dropout_1\": 0.45396324400132343,\u003cbr\u003e    \"n_units_l2\": 16,\u003cbr\u003e    \"dropout_2\": 0.26773459006764677,\u003cbr\u003e    \"lr\": 2.7640129258681872e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 8,\u003cbr\u003e  \"values\": [\u003cbr\u003e    97864.0,\u003cbr\u003e    0.7609375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 116,\u003cbr\u003e    \"dropout_0\": 0.2970625718001778,\u003cbr\u003e    \"n_units_l1\": 30,\u003cbr\u003e    \"dropout_1\": 0.43106946620592224,\u003cbr\u003e    \"n_units_l2\": 86,\u003cbr\u003e    \"dropout_2\": 0.3736820996519109,\u003cbr\u003e    \"lr\": 0.0009291906601903653\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 10,\u003cbr\u003e  \"values\": [\u003cbr\u003e    62082.0,\u003cbr\u003e    0.7515625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 71,\u003cbr\u003e    \"dropout_0\": 0.4455098018463368,\u003cbr\u003e    \"n_units_l1\": 44,\u003cbr\u003e    \"dropout_1\": 0.472109887511219,\u003cbr\u003e    \"n_units_l2\": 61,\u003cbr\u003e    \"dropout_2\": 0.3846712887013255,\u003cbr\u003e    \"lr\": 0.005665211807921356\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 11,\u003cbr\u003e  \"values\": [\u003cbr\u003e    104634.0,\u003cbr\u003e    0.62734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 127,\u003cbr\u003e    \"dropout_0\": 0.3707521452631011,\u003cbr\u003e    \"n_units_l1\": 22,\u003cbr\u003e    \"dropout_1\": 0.33517694983774826,\u003cbr\u003e    \"n_units_l2\": 71,\u003cbr\u003e    \"dropout_2\": 0.2713065251041037,\u003cbr\u003e    \"lr\": 0.00025186414269041225\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 13,\u003cbr\u003e  \"values\": [\u003cbr\u003e    95471.0,\u003cbr\u003e    0.28984375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 107,\u003cbr\u003e    \"dropout_0\": 0.41667077671888064,\u003cbr\u003e    \"n_units_l1\": 99,\u003cbr\u003e    \"dropout_1\": 0.22380672324989184,\u003cbr\u003e    \"lr\": 0.09899711065571924\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 14,\u003cbr\u003e  \"values\": [\u003cbr\u003e    57962.0,\u003cbr\u003e    0.7578125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 73,\u003cbr\u003e    \"dropout_0\": 0.26571659185006585,\u003cbr\u003e    \"lr\": 0.0003125344907998128\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 15,\u003cbr\u003e  \"values\": [\u003cbr\u003e    16810.0,\u003cbr\u003e    0.32265625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 19,\u003cbr\u003e    \"dropout_0\": 0.30809571762471333,\u003cbr\u003e    \"n_units_l1\": 66,\u003cbr\u003e    \"dropout_1\": 0.33603218539494384,\u003cbr\u003e    \"lr\": 1.4524079845020339e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 16,\u003cbr\u003e  \"values\": [\u003cbr\u003e    19424.0,\u003cbr\u003e    0.53515625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 22,\u003cbr\u003e    \"dropout_0\": 0.45123051205546844,\u003cbr\u003e    \"n_units_l1\": 68,\u003cbr\u003e    \"dropout_1\": 0.2627584262841681,\u003cbr\u003e    \"lr\": 9.808816843090413e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 18,\u003cbr\u003e  \"values\": [\u003cbr\u003e    97232.0,\u003cbr\u003e    0.4109375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 122,\u003cbr\u003e    \"dropout_0\": 0.2686784967046938,\u003cbr\u003e    \"n_units_l1\": 12,\u003cbr\u003e    \"dropout_1\": 0.46459889314352804,\u003cbr\u003e    \"lr\": 3.272429068001273e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 19,\u003cbr\u003e  \"values\": [\u003cbr\u003e    95618.0,\u003cbr\u003e    0.321875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 112,\u003cbr\u003e    \"dropout_0\": 0.34038962207533796,\u003cbr\u003e    \"n_units_l1\": 37,\u003cbr\u003e    \"dropout_1\": 0.370031594263189,\u003cbr\u003e    \"n_units_l2\": 78,\u003cbr\u003e    \"dropout_2\": 0.28306643822876754,\u003cbr\u003e    \"lr\": 1.7325320035942996e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 20,\u003cbr\u003e  \"values\": [\u003cbr\u003e    27080.0,\u003cbr\u003e    0.7765625\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 20,\u003cbr\u003e    \"dropout_0\": 0.3273279823616281,\u003cbr\u003e    \"n_units_l1\": 70,\u003cbr\u003e    \"dropout_1\": 0.2453388467388017,\u003cbr\u003e    \"n_units_l2\": 125,\u003cbr\u003e    \"dropout_2\": 0.47269420763406284,\u003cbr\u003e    \"lr\": 0.002929526724440705\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 21,\u003cbr\u003e  \"values\": [\u003cbr\u003e    24308.0,\u003cbr\u003e    0.22734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 26,\u003cbr\u003e    \"dropout_0\": 0.4493894740688696,\u003cbr\u003e    \"n_units_l1\": 109,\u003cbr\u003e    \"dropout_1\": 0.46893110421037754,\u003cbr\u003e    \"lr\": 2.5270947092836804e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 22,\u003cbr\u003e  \"values\": [\u003cbr\u003e    54582.0,\u003cbr\u003e    0.76796875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 65,\u003cbr\u003e    \"dropout_0\": 0.20890545777072234,\u003cbr\u003e    \"n_units_l1\": 38,\u003cbr\u003e    \"dropout_1\": 0.4718800247553403,\u003cbr\u003e    \"n_units_l2\": 24,\u003cbr\u003e    \"dropout_2\": 0.23337859340181308,\u003cbr\u003e    \"lr\": 0.0017222490371770582\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 23,\u003cbr\u003e  \"values\": [\u003cbr\u003e    85190.0,\u003cbr\u003e    0.76953125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 95,\u003cbr\u003e    \"dropout_0\": 0.43244640582875415,\u003cbr\u003e    \"n_units_l1\": 102,\u003cbr\u003e    \"dropout_1\": 0.3436539700666543,\u003cbr\u003e    \"lr\": 0.0005805382194328283\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 26,\u003cbr\u003e  \"values\": [\u003cbr\u003e    56640.0,\u003cbr\u003e    0.60859375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 70,\u003cbr\u003e    \"dropout_0\": 0.46062274278466003,\u003cbr\u003e    \"n_units_l1\": 22,\u003cbr\u003e    \"dropout_1\": 0.36239159221834416,\u003cbr\u003e    \"lr\": 0.04045728543263179\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 28,\u003cbr\u003e  \"values\": [\u003cbr\u003e    73176.0,\u003cbr\u003e    0.79296875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 3,\u003cbr\u003e    \"n_units_l0\": 86,\u003cbr\u003e    \"dropout_0\": 0.21233472277542795,\u003cbr\u003e    \"n_units_l1\": 47,\u003cbr\u003e    \"dropout_1\": 0.4494032364666494,\u003cbr\u003e    \"n_units_l2\": 30,\u003cbr\u003e    \"dropout_2\": 0.21023425482532482,\u003cbr\u003e    \"lr\": 0.002555570197043357\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 29,\u003cbr\u003e  \"values\": [\u003cbr\u003e    99048.0,\u003cbr\u003e    0.6734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 114,\u003cbr\u003e    \"dropout_0\": 0.46532946395255326,\u003cbr\u003e    \"n_units_l1\": 78,\u003cbr\u003e    \"dropout_1\": 0.4160057476702988,\u003cbr\u003e    \"lr\": 0.0001409867202596218\u003cbr\u003e  }\u003cbr\u003e}"],"x":[27104.0,43631.0,96074.0,49008.0,45825.0,74336.0,65117.0,88080.0,97864.0,62082.0,104634.0,95471.0,57962.0,16810.0,19424.0,97232.0,95618.0,27080.0,24308.0,54582.0,85190.0,56640.0,73176.0,99048.0],"y":[0.684375,0.47109375,0.83203125,0.7546875,0.09375,0.66875,0.55078125,0.37421875,0.7609375,0.7515625,0.62734375,0.28984375,0.7578125,0.32265625,0.53515625,0.4109375,0.321875,0.7765625,0.22734375,0.76796875,0.76953125,0.60859375,0.79296875,0.6734375],"type":"scatter"},{"hovertemplate":"%{text}\u003cextra\u003eBest Trial\u003c\u002fextra\u003e","marker":{"color":[9,12,17,24,25,27],"colorbar":{"title":{"text":"Best Trial"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{\u003cbr\u003e  \"number\": 9,\u003cbr\u003e  \"values\": [\u003cbr\u003e    49212.0,\u003cbr\u003e    0.83046875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 58,\u003cbr\u003e    \"dropout_0\": 0.31922230727827394,\u003cbr\u003e    \"n_units_l1\": 55,\u003cbr\u003e    \"dropout_1\": 0.3920433915395535,\u003cbr\u003e    \"lr\": 0.003254047572913268\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 12,\u003cbr\u003e  \"values\": [\u003cbr\u003e    10508.0,\u003cbr\u003e    0.37734375\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 12,\u003cbr\u003e    \"dropout_0\": 0.35223917308372676,\u003cbr\u003e    \"n_units_l1\": 50,\u003cbr\u003e    \"dropout_1\": 0.3265377950737307,\u003cbr\u003e    \"lr\": 8.183619940878126e-05\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 17,\u003cbr\u003e  \"values\": [\u003cbr\u003e    16674.0,\u003cbr\u003e    0.6921875\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 21,\u003cbr\u003e    \"dropout_0\": 0.4705073530713875,\u003cbr\u003e    \"lr\": 0.00041309740054842225\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 24,\u003cbr\u003e  \"values\": [\u003cbr\u003e    34460.0,\u003cbr\u003e    0.79453125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 40,\u003cbr\u003e    \"dropout_0\": 0.42528746765625214,\u003cbr\u003e    \"n_units_l1\": 62,\u003cbr\u003e    \"dropout_1\": 0.42795206381578554,\u003cbr\u003e    \"lr\": 0.005605956922819534\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 25,\u003cbr\u003e  \"values\": [\u003cbr\u003e    51610.0,\u003cbr\u003e    0.84453125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 1,\u003cbr\u003e    \"n_units_l0\": 65,\u003cbr\u003e    \"dropout_0\": 0.27448413925833665,\u003cbr\u003e    \"lr\": 0.003858207762825232\u003cbr\u003e  }\u003cbr\u003e}","{\u003cbr\u003e  \"number\": 27,\u003cbr\u003e  \"values\": [\u003cbr\u003e    26208.0,\u003cbr\u003e    0.778125\u003cbr\u003e  ],\u003cbr\u003e  \"params\": {\u003cbr\u003e    \"n_layers\": 2,\u003cbr\u003e    \"n_units_l0\": 28,\u003cbr\u003e    \"dropout_0\": 0.2952516989645517,\u003cbr\u003e    \"n_units_l1\": 112,\u003cbr\u003e    \"dropout_1\": 0.4715487709461201,\u003cbr\u003e    \"lr\": 0.0012221840920527281\u003cbr\u003e  }\u003cbr\u003e}"],"x":[49212.0,10508.0,16674.0,34460.0,51610.0,26208.0],"y":[0.83046875,0.37734375,0.6921875,0.79453125,0.84453125,0.778125],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 127-130

Fetch the list of trials on the Pareto front with :attr:`~optuna.study.Study.best_trials`.

For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 130-139

.. code-block:: Python


    print(f"Number of trials on the Pareto front: {len(study.best_trials)}")

    trial_with_highest_accuracy = max(study.best_trials, key=lambda t: t.values[1])
    print(f"Trial with highest accuracy: ")
    print(f"\tnumber: {trial_with_highest_accuracy.number}")
    print(f"\tparams: {trial_with_highest_accuracy.params}")
    print(f"\tvalues: {trial_with_highest_accuracy.values}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Number of trials on the Pareto front: 6
    Trial with highest accuracy: 
            number: 25
            params: {'n_layers': 1, 'n_units_l0': 65, 'dropout_0': 0.27448413925833665, 'lr': 0.003858207762825232}
            values: [51610.0, 0.84453125]




.. GENERATED FROM PYTHON SOURCE LINES 140-141

Learn which hyperparameters are affecting the flops most with hyperparameter importance.

.. GENERATED FROM PYTHON SOURCE LINES 141-144

.. code-block:: Python

    optuna.visualization.plot_param_importances(
        study, target=lambda t: t.values[0], target_name="flops"
    )





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.30.0.min.js"></script>                <div id="f7bdb2d9-f037-44d4-8f92-f11dee86e0ae" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("f7bdb2d9-f037-44d4-8f92-f11dee86e0ae")) {                    Plotly.newPlot(                        "f7bdb2d9-f037-44d4-8f92-f11dee86e0ae",                        [{"cliponaxis":false,"hovertemplate":["n_layers (IntDistribution): 0.0001824220480971327\u003cextra\u003e\u003c\u002fextra\u003e","lr (FloatDistribution): 0.0008627981571000118\u003cextra\u003e\u003c\u002fextra\u003e","dropout_0 (FloatDistribution): 0.002568761940406506\u003cextra\u003e\u003c\u002fextra\u003e","n_units_l0 (IntDistribution): 0.9963860178543963\u003cextra\u003e\u003c\u002fextra\u003e"],"name":"flops","orientation":"h","text":["\u003c0.01","\u003c0.01","\u003c0.01","1.00"],"textposition":"outside","x":[0.0001824220480971327,0.0008627981571000118,0.002568761940406506,0.9963860178543963],"y":["n_layers","lr","dropout_0","n_units_l0"],"type":"bar"}],                        {"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Hyperparameter Importance"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 54.427 seconds)


.. _sphx_glr_download_tutorial_20_recipes_002_multi_objective.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 002_multi_objective.ipynb <002_multi_objective.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 002_multi_objective.py <002_multi_objective.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
