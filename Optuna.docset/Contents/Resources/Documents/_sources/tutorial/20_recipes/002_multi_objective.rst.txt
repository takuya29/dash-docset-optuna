
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/20_recipes/002_multi_objective.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorial_20_recipes_002_multi_objective.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_20_recipes_002_multi_objective.py:


.. _multi_objective:

Multi-objective Optimization with Optuna
========================================

This tutorial showcases Optuna's multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.

We use `thop <https://github.com/Lyken17/pytorch-OpCounter>`_ to measure FLOPS.

.. GENERATED FROM PYTHON SOURCE LINES 12-74

.. code-block:: default


    import thop
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision

    import optuna


    DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    DIR = ".."
    BATCHSIZE = 128
    N_TRAIN_EXAMPLES = BATCHSIZE * 30
    N_VALID_EXAMPLES = BATCHSIZE * 10


    def define_model(trial):
        n_layers = trial.suggest_int("n_layers", 1, 3)
        layers = []

        in_features = 28 * 28
        for i in range(n_layers):
            out_features = trial.suggest_int("n_units_l{}".format(i), 4, 128)
            layers.append(nn.Linear(in_features, out_features))
            layers.append(nn.ReLU())
            p = trial.suggest_float("dropout_{}".format(i), 0.2, 0.5)
            layers.append(nn.Dropout(p))

            in_features = out_features

        layers.append(nn.Linear(in_features, 10))
        layers.append(nn.LogSoftmax(dim=1))

        return nn.Sequential(*layers)


    # Defines training and evaluation.
    def train_model(model, optimizer, train_loader):
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
            optimizer.zero_grad()
            F.nll_loss(model(data), target).backward()
            optimizer.step()


    def eval_model(model, valid_loader):
        model.eval()
        correct = 0
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(valid_loader):
                data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
                pred = model(data).argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()

        accuracy = correct / N_VALID_EXAMPLES

        flops, _ = thop.profile(model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),), verbose=False)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 75-77

Define multi-objective objective function.
Objectives are FLOPS and accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 77-107

.. code-block:: default

    def objective(trial):
        train_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=True, download=True, transform=torchvision.transforms.ToTensor()
        )
        train_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )

        val_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=False, transform=torchvision.transforms.ToTensor()
        )
        val_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )
        model = define_model(trial).to(DEVICE)

        optimizer = torch.optim.Adam(
            model.parameters(), trial.suggest_float("lr", 1e-5, 1e-1, log=True)
        )

        for epoch in range(10):
            train_model(model, optimizer, train_loader)
        flops, accuracy = eval_model(model, val_loader)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 108-115

Run multi-objective optimization
--------------------------------

If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set ``directions`` to ``["minimize", "maximize"]``.

.. GENERATED FROM PYTHON SOURCE LINES 115-121

.. code-block:: default

    study = optuna.create_study(directions=["minimize", "maximize"])
    study.optimize(objective, n_trials=30, timeout=300)

    print("Number of finished trials: ", len(study.trials))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../FashionMNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0/26421880 [00:00<?, ?it/s]      0%|          | 12288/26421880 [00:00<05:41, 77374.83it/s]      0%|          | 43008/26421880 [00:00<03:02, 144395.56it/s]      0%|          | 102400/26421880 [00:00<01:46, 247702.46it/s]      1%|          | 217088/26421880 [00:00<01:00, 432004.57it/s]      2%|1         | 452608/26421880 [00:00<00:32, 806908.14it/s]      3%|3         | 921600/26421880 [00:00<00:16, 1528143.76it/s]      7%|7         | 1861632/26421880 [00:01<00:08, 2943265.80it/s]     14%|#4        | 3739648/26421880 [00:01<00:03, 5735285.09it/s]     26%|##5       | 6864896/26421880 [00:01<00:01, 10038826.15it/s]     37%|###7      | 9837568/26421880 [00:01<00:01, 12658019.59it/s]     47%|####7     | 12536832/26421880 [00:01<00:00, 13933965.63it/s]     58%|#####7    | 15251456/26421880 [00:01<00:00, 14848548.65it/s]     68%|######8   | 18012160/26421880 [00:02<00:00, 15558930.71it/s]     79%|#######8  | 20844544/26421880 [00:02<00:00, 16147128.18it/s]     90%|########9 | 23701504/26421880 [00:02<00:00, 16662392.31it/s]    26422272it [00:02, 10713831.87it/s]                              
    Extracting ../FashionMNIST/raw/train-images-idx3-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0/29515 [00:00<?, ?it/s]     49%|####8     | 14336/29515 [00:00<00:00, 92378.51it/s]    29696it [00:00, 190495.06it/s]                          
    Extracting ../FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0/4422102 [00:00<?, ?it/s]      0%|          | 14336/4422102 [00:00<00:48, 90852.36it/s]      1%|          | 44032/4422102 [00:00<00:29, 147731.86it/s]      2%|2         | 104448/4422102 [00:00<00:16, 254575.92it/s]      5%|5         | 224256/4422102 [00:00<00:09, 452727.57it/s]     11%|#         | 464896/4422102 [00:00<00:04, 837177.13it/s]     21%|##1       | 946176/4422102 [00:00<00:02, 1585890.47it/s]     43%|####3     | 1908736/4422102 [00:01<00:00, 3054988.56it/s]     87%|########6 | 3832832/4422102 [00:01<00:00, 5951691.47it/s]    4422656it [00:01, 3477152.86it/s]                             
    Extracting ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0/5148 [00:00<?, ?it/s]    6144it [00:00, 23534067.38it/s]         
    Extracting ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw

    Number of finished trials:  30




.. GENERATED FROM PYTHON SOURCE LINES 122-123

Check trials on Pareto front visually.

.. GENERATED FROM PYTHON SOURCE LINES 123-126

.. code-block:: default

    optuna.visualization.plot_pareto_front(study, target_names=["FLOPS", "accuracy"])







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>                <div id="c8727ace-11d5-4308-ab24-b3e4eb60e12d" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("c8727ace-11d5-4308-ab24-b3e4eb60e12d")) {                    Plotly.newPlot(                        "c8727ace-11d5-4308-ab24-b3e4eb60e12d",                        [{"hovertemplate":"%{text}<extra>Trial</extra>","marker":{"color":[2,3,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28,29],"colorbar":{"title":{"text":"Trial"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 2,<br>  \"values\": [<br>    93058.0,<br>    0.62109375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 111,<br>    \"dropout_0\": 0.38756419124449826,<br>    \"n_units_l1\": 37,<br>    \"dropout_1\": 0.41148881587420627,<br>    \"n_units_l2\": 41,<br>    \"dropout_2\": 0.29241951321422804,<br>    \"lr\": 0.00012465783630300143<br>  }<br>}","{<br>  \"number\": 3,<br>  \"values\": [<br>    47343.0,<br>    0.509375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 51,<br>    \"dropout_0\": 0.32910653407691026,<br>    \"n_units_l1\": 51,<br>    \"dropout_1\": 0.2972566186132962,<br>    \"n_units_l2\": 78,<br>    \"dropout_2\": 0.4911038469752409,<br>    \"lr\": 8.494126467136322e-05<br>  }<br>}","{<br>  \"number\": 5,<br>  \"values\": [<br>    41616.0,<br>    0.69375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 45,<br>    \"dropout_0\": 0.29833639387031896,<br>    \"n_units_l1\": 107,<br>    \"dropout_1\": 0.35475736468381447,<br>    \"n_units_l2\": 13,<br>    \"dropout_2\": 0.46410248756833,<br>    \"lr\": 0.001892325425835412<br>  }<br>}","{<br>  \"number\": 6,<br>  \"values\": [<br>    60344.0,<br>    0.6015625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 76,<br>    \"dropout_0\": 0.2519600115732888,<br>    \"lr\": 2.265236349280119e-05<br>  }<br>}","{<br>  \"number\": 7,<br>  \"values\": [<br>    30860.0,<br>    0.74296875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 35,<br>    \"dropout_0\": 0.34497941211135097,<br>    \"n_units_l1\": 76,<br>    \"dropout_1\": 0.2377040338510116,<br>    \"lr\": 0.011562343300840898<br>  }<br>}","{<br>  \"number\": 9,<br>  \"values\": [<br>    80988.0,<br>    0.8078125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 102,<br>    \"dropout_0\": 0.37386341453009275,<br>    \"lr\": 0.0218906779155563<br>  }<br>}","{<br>  \"number\": 10,<br>  \"values\": [<br>    112072.0,<br>    0.196875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 116,<br>    \"dropout_0\": 0.3621783732865386,<br>    \"n_units_l1\": 102,<br>    \"dropout_1\": 0.26035554943763517,<br>    \"n_units_l2\": 83,<br>    \"dropout_2\": 0.4506244816236342,<br>    \"lr\": 0.05799298229153563<br>  }<br>}","{<br>  \"number\": 11,<br>  \"values\": [<br>    72254.0,<br>    0.67578125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 91,<br>    \"dropout_0\": 0.3951637982681116,<br>    \"lr\": 8.789494472274447e-05<br>  }<br>}","{<br>  \"number\": 12,<br>  \"values\": [<br>    57962.0,<br>    0.42421875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 73,<br>    \"dropout_0\": 0.3906233195215708,<br>    \"lr\": 0.06501306531458967<br>  }<br>}","{<br>  \"number\": 13,<br>  \"values\": [<br>    46396.0,<br>    0.784375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 54,<br>    \"dropout_0\": 0.40520507697992847,<br>    \"n_units_l1\": 30,<br>    \"dropout_1\": 0.34776500801937804,<br>    \"n_units_l2\": 61,<br>    \"dropout_2\": 0.32400753370743657,<br>    \"lr\": 0.0022734427496998574<br>  }<br>}","{<br>  \"number\": 14,<br>  \"values\": [<br>    31305.0,<br>    0.57890625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 36,<br>    \"dropout_0\": 0.4716958500017543,<br>    \"n_units_l1\": 21,<br>    \"dropout_1\": 0.2871761226894484,<br>    \"n_units_l2\": 75,<br>    \"dropout_2\": 0.2204850745106044,<br>    \"lr\": 0.00017362672687519168<br>  }<br>}","{<br>  \"number\": 15,<br>  \"values\": [<br>    34770.0,<br>    0.7875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 35,<br>    \"dropout_0\": 0.24133846250851396,<br>    \"n_units_l1\": 38,<br>    \"dropout_1\": 0.279135277006961,<br>    \"n_units_l2\": 125,<br>    \"dropout_2\": 0.39488651681389864,<br>    \"lr\": 0.007651362033563168<br>  }<br>}","{<br>  \"number\": 16,<br>  \"values\": [<br>    59550.0,<br>    0.7234375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 75,<br>    \"dropout_0\": 0.4949128800161268,<br>    \"lr\": 0.0002160507481555061<br>  }<br>}","{<br>  \"number\": 17,<br>  \"values\": [<br>    48398.0,<br>    0.34296875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 49,<br>    \"dropout_0\": 0.41016608034629753,<br>    \"n_units_l1\": 67,<br>    \"dropout_1\": 0.24208589090964233,<br>    \"n_units_l2\": 87,<br>    \"dropout_2\": 0.23231196944945617,<br>    \"lr\": 2.8560786099565946e-05<br>  }<br>}","{<br>  \"number\": 18,<br>  \"values\": [<br>    76226.0,<br>    0.78046875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 83,<br>    \"dropout_0\": 0.4828401305854214,<br>    \"n_units_l1\": 97,<br>    \"dropout_1\": 0.3438185464842372,<br>    \"n_units_l2\": 29,<br>    \"dropout_2\": 0.2519586971918744,<br>    \"lr\": 0.004819645539742925<br>  }<br>}","{<br>  \"number\": 19,<br>  \"values\": [<br>    73048.0,<br>    0.79609375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 92,<br>    \"dropout_0\": 0.4578448870138815,<br>    \"lr\": 0.0006629816538997323<br>  }<br>}","{<br>  \"number\": 20,<br>  \"values\": [<br>    31568.0,<br>    0.6546875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 38,<br>    \"dropout_0\": 0.49705176040713195,<br>    \"n_units_l1\": 37,<br>    \"dropout_1\": 0.4108455439633281,<br>    \"lr\": 0.0002533688151637096<br>  }<br>}","{<br>  \"number\": 21,<br>  \"values\": [<br>    87340.0,<br>    0.596875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 110,<br>    \"dropout_0\": 0.4160050533604502,<br>    \"lr\": 1.91498923346573e-05<br>  }<br>}","{<br>  \"number\": 22,<br>  \"values\": [<br>    64332.0,<br>    0.67578125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 66,<br>    \"dropout_0\": 0.21210726070188246,<br>    \"n_units_l1\": 128,<br>    \"dropout_1\": 0.38059180092832157,<br>    \"n_units_l2\": 30,<br>    \"dropout_2\": 0.42667492629545534,<br>    \"lr\": 0.00022349161250867158<br>  }<br>}","{<br>  \"number\": 23,<br>  \"values\": [<br>    13160.0,<br>    0.553125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 14,<br>    \"dropout_0\": 0.4456726203711783,<br>    \"n_units_l1\": 91,<br>    \"dropout_1\": 0.34775343445672446,<br>    \"lr\": 0.00018476097068331656<br>  }<br>}","{<br>  \"number\": 24,<br>  \"values\": [<br>    79400.0,<br>    0.77578125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 100,<br>    \"dropout_0\": 0.46337484330407175,<br>    \"lr\": 0.030133986048658867<br>  }<br>}","{<br>  \"number\": 25,<br>  \"values\": [<br>    110868.0,<br>    0.82265625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 118,<br>    \"dropout_0\": 0.27873197802187366,<br>    \"n_units_l1\": 101,<br>    \"dropout_1\": 0.2442239926243302,<br>    \"n_units_l2\": 58,<br>    \"dropout_2\": 0.47614036813159744,<br>    \"lr\": 0.003084875903518791<br>  }<br>}","{<br>  \"number\": 26,<br>  \"values\": [<br>    75676.0,<br>    0.64375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 69,<br>    \"dropout_0\": 0.338886091223922,<br>    \"n_units_l1\": 121,<br>    \"dropout_1\": 0.28591242995892396,<br>    \"n_units_l2\": 101,<br>    \"dropout_2\": 0.39097247462276813,<br>    \"lr\": 0.00015980910210418588<br>  }<br>}","{<br>  \"number\": 28,<br>  \"values\": [<br>    58756.0,<br>    0.5796875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 74,<br>    \"dropout_0\": 0.31663089167958136,<br>    \"lr\": 0.05188151615592437<br>  }<br>}","{<br>  \"number\": 29,<br>  \"values\": [<br>    23820.0,<br>    0.79140625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 30,<br>    \"dropout_0\": 0.45632555702270605,<br>    \"lr\": 0.0014992251045560965<br>  }<br>}"],"x":[93058.0,47343.0,41616.0,60344.0,30860.0,80988.0,112072.0,72254.0,57962.0,46396.0,31305.0,34770.0,59550.0,48398.0,76226.0,73048.0,31568.0,87340.0,64332.0,13160.0,79400.0,110868.0,75676.0,58756.0,23820.0],"y":[0.62109375,0.509375,0.69375,0.6015625,0.74296875,0.8078125,0.196875,0.67578125,0.42421875,0.784375,0.57890625,0.7875,0.7234375,0.34296875,0.78046875,0.79609375,0.6546875,0.596875,0.67578125,0.553125,0.77578125,0.82265625,0.64375,0.5796875,0.79140625],"type":"scatter"},{"hovertemplate":"%{text}<extra>Best Trial</extra>","marker":{"color":[0,1,4,8,27],"colorbar":{"title":{"text":"Best Trial"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 0,<br>  \"values\": [<br>    7940.0,<br>    0.6921875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 10,<br>    \"dropout_0\": 0.44206035284277645,<br>    \"lr\": 0.0005629432490258672<br>  }<br>}","{<br>  \"number\": 1,<br>  \"values\": [<br>    6298.0,<br>    0.090625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 7,<br>    \"dropout_0\": 0.21189255096946835,<br>    \"n_units_l1\": 70,<br>    \"dropout_1\": 0.28966317399901165,<br>    \"n_units_l2\": 4,<br>    \"dropout_2\": 0.44719981193703656,<br>    \"lr\": 4.6431550951165464e-05<br>  }<br>}","{<br>  \"number\": 4,<br>  \"values\": [<br>    44254.0,<br>    0.82734375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 51,<br>    \"dropout_0\": 0.23102841946303979,<br>    \"n_units_l1\": 70,<br>    \"dropout_1\": 0.44547624010899534,<br>    \"lr\": 0.006129513900139977<br>  }<br>}","{<br>  \"number\": 8,<br>  \"values\": [<br>    19056.0,<br>    0.796875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 24,<br>    \"dropout_0\": 0.42395580323725646,<br>    \"lr\": 0.005120743743621276<br>  }<br>}","{<br>  \"number\": 27,<br>  \"values\": [<br>    12170.0,<br>    0.75234375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 13,<br>    \"dropout_0\": 0.42374878986230535,<br>    \"n_units_l1\": 86,<br>    \"dropout_1\": 0.39027284575508525,<br>    \"lr\": 0.0014839918357693745<br>  }<br>}"],"x":[7940.0,6298.0,44254.0,19056.0,12170.0],"y":[0.6921875,0.090625,0.82734375,0.796875,0.75234375],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 127-130

Fetch the list of trials on the Pareto front with :attr:`~optuna.study.Study.best_trials`.

For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 130-139

.. code-block:: default


    print(f"Number of trials on the Pareto front: {len(study.best_trials)}")

    trial_with_highest_accuracy = max(study.best_trials, key=lambda t: t.values[1])
    print(f"Trial with highest accuracy: ")
    print(f"\tnumber: {trial_with_highest_accuracy.number}")
    print(f"\tparams: {trial_with_highest_accuracy.params}")
    print(f"\tvalues: {trial_with_highest_accuracy.values}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Number of trials on the Pareto front: 5
    Trial with highest accuracy: 
            number: 4
            params: {'n_layers': 2, 'n_units_l0': 51, 'dropout_0': 0.23102841946303979, 'n_units_l1': 70, 'dropout_1': 0.44547624010899534, 'lr': 0.006129513900139977}
            values: [44254.0, 0.82734375]




.. GENERATED FROM PYTHON SOURCE LINES 140-141

Learn which hyperparameters are affecting the flops most with hyperparameter importance.

.. GENERATED FROM PYTHON SOURCE LINES 141-144

.. code-block:: default

    optuna.visualization.plot_param_importances(
        study, target=lambda t: t.values[0], target_name="flops"
    )





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>                <div id="8359194a-40ac-4319-870b-116adb03b48c" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("8359194a-40ac-4319-870b-116adb03b48c")) {                    Plotly.newPlot(                        "8359194a-40ac-4319-870b-116adb03b48c",                        [{"cliponaxis":false,"hovertemplate":["n_layers (IntDistribution): 0.001030353345749823<extra></extra>","lr (FloatDistribution): 0.002617034899458944<extra></extra>","dropout_0 (FloatDistribution): 0.006249667362189823<extra></extra>","n_units_l0 (IntDistribution): 0.9901029443926014<extra></extra>"],"marker":{"color":"rgb(66,146,198)"},"orientation":"h","text":["<0.01","<0.01","<0.01","0.99"],"textposition":"outside","x":[0.001030353345749823,0.002617034899458944,0.006249667362189823,0.9901029443926014],"y":["n_layers","lr","dropout_0","n_units_l0"],"type":"bar"}],                        {"showlegend":false,"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Importance for flops"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 3 minutes  27.068 seconds)


.. _sphx_glr_download_tutorial_20_recipes_002_multi_objective.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 002_multi_objective.py <002_multi_objective.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 002_multi_objective.ipynb <002_multi_objective.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
