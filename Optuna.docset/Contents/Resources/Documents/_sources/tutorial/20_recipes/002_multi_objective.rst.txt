
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/20_recipes/002_multi_objective.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorial_20_recipes_002_multi_objective.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_20_recipes_002_multi_objective.py:


.. _multi_objective:

Multi-objective Optimization with Optuna
========================================

This tutorial showcases Optuna's multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.

We use `fvcore <https://github.com/facebookresearch/fvcore>`_ to measure FLOPS.

.. GENERATED FROM PYTHON SOURCE LINES 12-74

.. code-block:: default


    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision
    from fvcore.nn import FlopCountAnalysis

    import optuna


    DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    DIR = ".."
    BATCHSIZE = 128
    N_TRAIN_EXAMPLES = BATCHSIZE * 30
    N_VALID_EXAMPLES = BATCHSIZE * 10


    def define_model(trial):
        n_layers = trial.suggest_int("n_layers", 1, 3)
        layers = []

        in_features = 28 * 28
        for i in range(n_layers):
            out_features = trial.suggest_int("n_units_l{}".format(i), 4, 128)
            layers.append(nn.Linear(in_features, out_features))
            layers.append(nn.ReLU())
            p = trial.suggest_float("dropout_{}".format(i), 0.2, 0.5)
            layers.append(nn.Dropout(p))

            in_features = out_features

        layers.append(nn.Linear(in_features, 10))
        layers.append(nn.LogSoftmax(dim=1))

        return nn.Sequential(*layers)


    # Defines training and evaluation.
    def train_model(model, optimizer, train_loader):
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
            optimizer.zero_grad()
            F.nll_loss(model(data), target).backward()
            optimizer.step()


    def eval_model(model, valid_loader):
        model.eval()
        correct = 0
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(valid_loader):
                data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
                pred = model(data).argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()

        accuracy = correct / N_VALID_EXAMPLES

        flops = FlopCountAnalysis(model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),)).total()
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 75-77

Define multi-objective objective function.
Objectives are FLOPS and accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 77-107

.. code-block:: default

    def objective(trial):
        train_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=True, download=True, transform=torchvision.transforms.ToTensor()
        )
        train_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )

        val_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=False, transform=torchvision.transforms.ToTensor()
        )
        val_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )
        model = define_model(trial).to(DEVICE)

        optimizer = torch.optim.Adam(
            model.parameters(), trial.suggest_float("lr", 1e-5, 1e-1, log=True)
        )

        for epoch in range(10):
            train_model(model, optimizer, train_loader)
        flops, accuracy = eval_model(model, val_loader)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 108-115

Run multi-objective optimization
--------------------------------

If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set ``directions`` to ``["minimize", "maximize"]``.

.. GENERATED FROM PYTHON SOURCE LINES 115-121

.. code-block:: default

    study = optuna.create_study(directions=["minimize", "maximize"])
    study.optimize(objective, n_trials=30, timeout=300)

    print("Number of finished trials: ", len(study.trials))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../FashionMNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0/26421880 [00:00<?, ?it/s]      0%|          | 39936/26421880 [00:00<01:09, 379235.40it/s]      0%|          | 102400/26421880 [00:00<01:11, 366371.47it/s]      1%|1         | 376832/26421880 [00:00<00:21, 1205846.45it/s]      4%|3         | 945152/26421880 [00:00<00:11, 2180773.96it/s]     11%|#1        | 2928640/26421880 [00:00<00:03, 6973993.78it/s]     24%|##4       | 6365184/26421880 [00:00<00:01, 12166150.03it/s]     39%|###8      | 10256384/26421880 [00:00<00:00, 18532234.24it/s]     53%|#####2    | 13928448/26421880 [00:01<00:00, 19524367.17it/s]     67%|######7   | 17726464/26421880 [00:01<00:00, 23474167.62it/s]     81%|########  | 21361664/26421880 [00:01<00:00, 22594880.61it/s]     95%|#########4| 25042944/26421880 [00:01<00:00, 25408653.23it/s]    26422272it [00:01, 16648790.64it/s]                              
    Extracting ../FashionMNIST/raw/train-images-idx3-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0/29515 [00:00<?, ?it/s]    29696it [00:00, 325610.23it/s]           
    Extracting ../FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0/4422102 [00:00<?, ?it/s]      1%|          | 41984/4422102 [00:00<00:10, 407154.85it/s]      2%|2         | 105472/4422102 [00:00<00:11, 381381.82it/s]      7%|7         | 317440/4422102 [00:00<00:04, 1009430.14it/s]     19%|#9        | 855040/4422102 [00:00<00:01, 2011754.26it/s]     59%|#####9    | 2609152/4422102 [00:00<00:00, 6329568.79it/s]    4422656it [00:00, 5984803.33it/s]                             
    Extracting ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0/5148 [00:00<?, ?it/s]    6144it [00:00, 31619391.14it/s]         
    Extracting ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw

    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Unsupported operator aten::log_softmax encountered 1 time(s)
    Number of finished trials:  30




.. GENERATED FROM PYTHON SOURCE LINES 122-123

Check trials on Pareto front visually.

.. GENERATED FROM PYTHON SOURCE LINES 123-126

.. code-block:: default

    optuna.visualization.plot_pareto_front(study, target_names=["FLOPS", "accuracy"])







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.18.0.min.js"></script>                <div id="6019762f-54e8-4e65-8f28-2475980b2d13" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("6019762f-54e8-4e65-8f28-2475980b2d13")) {                    Plotly.newPlot(                        "6019762f-54e8-4e65-8f28-2475980b2d13",                        [{"hovertemplate":"%{text}<extra>Trial</extra>","marker":{"color":[0,1,2,3,4,6,7,8,10,11,13,14,16,17,18,19,21,22,24,25,26,27,28,29],"colorbar":{"title":{"text":"Trial"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 0,<br>  \"values\": [<br>    84164.0,<br>    0.82890625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 106,<br>    \"dropout_0\": 0.2918206317877167,<br>    \"lr\": 0.015673924980702105<br>  }<br>}","{<br>  \"number\": 1,<br>  \"values\": [<br>    96868.0,<br>    0.828125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 122,<br>    \"dropout_0\": 0.4546254411964019,<br>    \"lr\": 0.0012295050488982696<br>  }<br>}","{<br>  \"number\": 2,<br>  \"values\": [<br>    7146.0,<br>    0.6359375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 9,<br>    \"dropout_0\": 0.28197048811660147,<br>    \"lr\": 0.0300112786522792<br>  }<br>}","{<br>  \"number\": 3,<br>  \"values\": [<br>    70060.0,<br>    0.77890625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 85,<br>    \"dropout_0\": 0.3838875900486325,<br>    \"n_units_l1\": 36,<br>    \"dropout_1\": 0.36056955306999916,<br>    \"lr\": 0.014424103683722638<br>  }<br>}","{<br>  \"number\": 4,<br>  \"values\": [<br>    33238.0,<br>    0.56015625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 37,<br>    \"dropout_0\": 0.3550656594308635,<br>    \"n_units_l1\": 90,<br>    \"dropout_1\": 0.4586285353719242,<br>    \"lr\": 3.635298867876687e-05<br>  }<br>}","{<br>  \"number\": 6,<br>  \"values\": [<br>    107643.0,<br>    0.275<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 117,<br>    \"dropout_0\": 0.3518913198430984,<br>    \"n_units_l1\": 75,<br>    \"dropout_1\": 0.21140609059143195,<br>    \"n_units_l2\": 84,<br>    \"dropout_2\": 0.3105826643732106,<br>    \"lr\": 0.0890142474670039<br>  }<br>}","{<br>  \"number\": 7,<br>  \"values\": [<br>    75430.0,<br>    0.8140625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 95,<br>    \"dropout_0\": 0.26786448212275765,<br>    \"lr\": 0.0005341483807182528<br>  }<br>}","{<br>  \"number\": 8,<br>  \"values\": [<br>    100164.0,<br>    0.8171875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 114,<br>    \"dropout_0\": 0.31198094642329366,<br>    \"n_units_l1\": 87,<br>    \"dropout_1\": 0.3929165018117785,<br>    \"lr\": 0.0029289595016268933<br>  }<br>}","{<br>  \"number\": 10,<br>  \"values\": [<br>    89442.0,<br>    0.1015625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 108,<br>    \"dropout_0\": 0.3134758547966564,<br>    \"n_units_l1\": 16,<br>    \"dropout_1\": 0.3987593431562668,<br>    \"n_units_l2\": 117,<br>    \"dropout_2\": 0.40931558285621217,<br>    \"lr\": 0.03376113175722865<br>  }<br>}","{<br>  \"number\": 11,<br>  \"values\": [<br>    94640.0,<br>    0.7828125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 112,<br>    \"dropout_0\": 0.4844288084051654,<br>    \"n_units_l1\": 56,<br>    \"dropout_1\": 0.2665314661772561,<br>    \"lr\": 0.0007270649980559312<br>  }<br>}","{<br>  \"number\": 13,<br>  \"values\": [<br>    84186.0,<br>    0.61015625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 89,<br>    \"dropout_0\": 0.39171411489278796,<br>    \"n_units_l1\": 92,<br>    \"dropout_1\": 0.26788685776291504,<br>    \"n_units_l2\": 61,<br>    \"dropout_2\": 0.27217154140943095,<br>    \"lr\": 0.029190697301230882<br>  }<br>}","{<br>  \"number\": 14,<br>  \"values\": [<br>    5558.0,<br>    0.60234375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 7,<br>    \"dropout_0\": 0.3307007873086244,<br>    \"lr\": 0.000508693735547636<br>  }<br>}","{<br>  \"number\": 16,<br>  \"values\": [<br>    79400.0,<br>    0.66171875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 100,<br>    \"dropout_0\": 0.2571796301316849,<br>    \"lr\": 6.41415409279927e-05<br>  }<br>}","{<br>  \"number\": 17,<br>  \"values\": [<br>    38187.0,<br>    0.27890625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 46,<br>    \"dropout_0\": 0.3022981627024828,<br>    \"n_units_l1\": 31,<br>    \"dropout_1\": 0.2232439453047573,<br>    \"n_units_l2\": 17,<br>    \"dropout_2\": 0.26144230909761224,<br>    \"lr\": 2.8065411195587847e-05<br>  }<br>}","{<br>  \"number\": 18,<br>  \"values\": [<br>    14518.0,<br>    0.609375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 17,<br>    \"dropout_0\": 0.3079645350376427,<br>    \"n_units_l1\": 10,<br>    \"dropout_1\": 0.24063234176918502,<br>    \"n_units_l2\": 51,<br>    \"dropout_2\": 0.2963927405716508,<br>    \"lr\": 0.0006366087692034033<br>  }<br>}","{<br>  \"number\": 19,<br>  \"values\": [<br>    79400.0,<br>    0.78984375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 100,<br>    \"dropout_0\": 0.22706462320945697,<br>    \"lr\": 0.028575283794561798<br>  }<br>}","{<br>  \"number\": 21,<br>  \"values\": [<br>    80010.0,<br>    0.81484375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 86,<br>    \"dropout_0\": 0.36291766773243866,<br>    \"n_units_l1\": 71,<br>    \"dropout_1\": 0.33482900907114654,<br>    \"n_units_l2\": 80,<br>    \"dropout_2\": 0.25512408696559935,<br>    \"lr\": 0.005641778637413352<br>  }<br>}","{<br>  \"number\": 22,<br>  \"values\": [<br>    83930.0,<br>    0.78359375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 93,<br>    \"dropout_0\": 0.2694000260493555,<br>    \"n_units_l1\": 106,<br>    \"dropout_1\": 0.24238038002254514,<br>    \"n_units_l2\": 10,<br>    \"dropout_2\": 0.20318569669790537,<br>    \"lr\": 0.0059574272797160484<br>  }<br>}","{<br>  \"number\": 24,<br>  \"values\": [<br>    35730.0,<br>    0.74296875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 45,<br>    \"dropout_0\": 0.2305267668722813,<br>    \"lr\": 0.00039590432523458626<br>  }<br>}","{<br>  \"number\": 25,<br>  \"values\": [<br>    18624.0,<br>    0.43046875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 22,<br>    \"dropout_0\": 0.2645430353841823,<br>    \"n_units_l1\": 43,<br>    \"dropout_1\": 0.4779942458014075,<br>    \"lr\": 2.4104929230810806e-05<br>  }<br>}","{<br>  \"number\": 26,<br>  \"values\": [<br>    70112.0,<br>    0.74453125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 77,<br>    \"dropout_0\": 0.207846931244082,<br>    \"n_units_l1\": 112,<br>    \"dropout_1\": 0.4623494902006593,<br>    \"lr\": 0.00032974376454409217<br>  }<br>}","{<br>  \"number\": 27,<br>  \"values\": [<br>    89722.0,<br>    0.7265625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 113,<br>    \"dropout_0\": 0.24396201902223694,<br>    \"lr\": 0.0001349166309249136<br>  }<br>}","{<br>  \"number\": 28,<br>  \"values\": [<br>    34643.0,<br>    0.65078125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 39,<br>    \"dropout_0\": 0.46884344229839303,<br>    \"n_units_l1\": 83,<br>    \"dropout_1\": 0.2970609336147676,<br>    \"lr\": 0.00017839004595600282<br>  }<br>}","{<br>  \"number\": 29,<br>  \"values\": [<br>    4764.0,<br>    0.584375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 6,<br>    \"dropout_0\": 0.39484528700370836,<br>    \"lr\": 0.0003847092343749864<br>  }<br>}"],"x":[84164.0,96868.0,7146.0,70060.0,33238.0,107643.0,75430.0,100164.0,89442.0,94640.0,84186.0,5558.0,79400.0,38187.0,14518.0,79400.0,80010.0,83930.0,35730.0,18624.0,70112.0,89722.0,34643.0,4764.0],"y":[0.82890625,0.828125,0.6359375,0.77890625,0.56015625,0.275,0.8140625,0.8171875,0.1015625,0.7828125,0.61015625,0.60234375,0.66171875,0.27890625,0.609375,0.78984375,0.81484375,0.78359375,0.74296875,0.43046875,0.74453125,0.7265625,0.65078125,0.584375],"type":"scatter"},{"hovertemplate":"%{text}<extra>Best Trial</extra>","marker":{"color":[5,9,12,15,20,23],"colorbar":{"title":{"text":"Best Trial"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 5,<br>  \"values\": [<br>    43289.0,<br>    0.815625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 47,<br>    \"dropout_0\": 0.2462866665594412,<br>    \"n_units_l1\": 113,<br>    \"dropout_1\": 0.4644650232270454,<br>    \"lr\": 0.0017412314322320683<br>  }<br>}","{<br>  \"number\": 9,<br>  \"values\": [<br>    24614.0,<br>    0.77578125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 31,<br>    \"dropout_0\": 0.30939543451751367,<br>    \"lr\": 0.026782393084657803<br>  }<br>}","{<br>  \"number\": 12,<br>  \"values\": [<br>    74576.0,<br>    0.81875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 92,<br>    \"dropout_0\": 0.3982767049237088,<br>    \"n_units_l1\": 24,<br>    \"dropout_1\": 0.2590174429839756,<br>    \"lr\": 0.007742272623228435<br>  }<br>}","{<br>  \"number\": 15,<br>  \"values\": [<br>    26969.0,<br>    0.79140625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 31,<br>    \"dropout_0\": 0.40459585473417475,<br>    \"n_units_l1\": 65,<br>    \"dropout_1\": 0.4117056056526106,<br>    \"lr\": 0.006519992213795596<br>  }<br>}","{<br>  \"number\": 20,<br>  \"values\": [<br>    84164.0,<br>    0.83828125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 106,<br>    \"dropout_0\": 0.3234014701382485,<br>    \"lr\": 0.003177990722747878<br>  }<br>}","{<br>  \"number\": 23,<br>  \"values\": [<br>    4764.0,<br>    0.69453125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 6,<br>    \"dropout_0\": 0.32917235794253863,<br>    \"lr\": 0.006008063813097975<br>  }<br>}"],"x":[43289.0,24614.0,74576.0,26969.0,84164.0,4764.0],"y":[0.815625,0.77578125,0.81875,0.79140625,0.83828125,0.69453125],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 127-130

Fetch the list of trials on the Pareto front with :attr:`~optuna.study.Study.best_trials`.

For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 130-139

.. code-block:: default


    print(f"Number of trials on the Pareto front: {len(study.best_trials)}")

    trial_with_highest_accuracy = max(study.best_trials, key=lambda t: t.values[1])
    print(f"Trial with highest accuracy: ")
    print(f"\tnumber: {trial_with_highest_accuracy.number}")
    print(f"\tparams: {trial_with_highest_accuracy.params}")
    print(f"\tvalues: {trial_with_highest_accuracy.values}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Number of trials on the Pareto front: 6
    Trial with highest accuracy: 
            number: 20
            params: {'n_layers': 1, 'n_units_l0': 106, 'dropout_0': 0.3234014701382485, 'lr': 0.003177990722747878}
            values: [84164.0, 0.83828125]




.. GENERATED FROM PYTHON SOURCE LINES 140-141

Learn which hyperparameters are affecting the flops most with hyperparameter importance.

.. GENERATED FROM PYTHON SOURCE LINES 141-144

.. code-block:: default

    optuna.visualization.plot_param_importances(
        study, target=lambda t: t.values[0], target_name="flops"
    )





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.18.0.min.js"></script>                <div id="a39aba9b-7231-4974-ba97-fa4de3aea3a0" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("a39aba9b-7231-4974-ba97-fa4de3aea3a0")) {                    Plotly.newPlot(                        "a39aba9b-7231-4974-ba97-fa4de3aea3a0",                        [{"cliponaxis":false,"hovertemplate":["n_layers (IntDistribution): 0.0006532360053519128<extra></extra>","lr (FloatDistribution): 0.0009900550790740135<extra></extra>","dropout_0 (FloatDistribution): 0.0018518802327125957<extra></extra>","n_units_l0 (IntDistribution): 0.9965048286828615<extra></extra>"],"marker":{"color":"rgb(66,146,198)"},"orientation":"h","text":["<0.01","<0.01","<0.01","1.00"],"textposition":"outside","x":[0.0006532360053519128,0.0009900550790740135,0.0018518802327125957,0.9965048286828615],"y":["n_layers","lr","dropout_0","n_units_l0"],"type":"bar"}],                        {"showlegend":false,"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Importance for flops"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  49.198 seconds)


.. _sphx_glr_download_tutorial_20_recipes_002_multi_objective.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 002_multi_objective.py <002_multi_objective.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 002_multi_objective.ipynb <002_multi_objective.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
