
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/20_recipes/002_multi_objective.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorial_20_recipes_002_multi_objective.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_20_recipes_002_multi_objective.py:


.. _multi_objective:

Multi-objective Optimization with Optuna
========================================

This tutorial showcases Optuna's multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.

We use `thop <https://github.com/Lyken17/pytorch-OpCounter>`_ to measure FLOPS.

.. GENERATED FROM PYTHON SOURCE LINES 12-74

.. code-block:: default


    import thop
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision

    import optuna


    DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    DIR = ".."
    BATCHSIZE = 128
    N_TRAIN_EXAMPLES = BATCHSIZE * 30
    N_VALID_EXAMPLES = BATCHSIZE * 10


    def define_model(trial):
        n_layers = trial.suggest_int("n_layers", 1, 3)
        layers = []

        in_features = 28 * 28
        for i in range(n_layers):
            out_features = trial.suggest_int("n_units_l{}".format(i), 4, 128)
            layers.append(nn.Linear(in_features, out_features))
            layers.append(nn.ReLU())
            p = trial.suggest_float("dropout_{}".format(i), 0.2, 0.5)
            layers.append(nn.Dropout(p))

            in_features = out_features

        layers.append(nn.Linear(in_features, 10))
        layers.append(nn.LogSoftmax(dim=1))

        return nn.Sequential(*layers)


    # Defines training and evaluation.
    def train_model(model, optimizer, train_loader):
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
            optimizer.zero_grad()
            F.nll_loss(model(data), target).backward()
            optimizer.step()


    def eval_model(model, valid_loader):
        model.eval()
        correct = 0
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(valid_loader):
                data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
                pred = model(data).argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()

        accuracy = correct / N_VALID_EXAMPLES

        flops, _ = thop.profile(model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),), verbose=False)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 75-77

Define multi-objective objective function.
Objectives are FLOPS and accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 77-107

.. code-block:: default

    def objective(trial):
        train_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=True, download=True, transform=torchvision.transforms.ToTensor()
        )
        train_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )

        val_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=False, transform=torchvision.transforms.ToTensor()
        )
        val_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )
        model = define_model(trial).to(DEVICE)

        optimizer = torch.optim.Adam(
            model.parameters(), trial.suggest_float("lr", 1e-5, 1e-1, log=True)
        )

        for epoch in range(10):
            train_model(model, optimizer, train_loader)
        flops, accuracy = eval_model(model, val_loader)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 108-115

Run multi-objective optimization
--------------------------------

If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set ``directions`` to ``["minimize", "maximize"]``.

.. GENERATED FROM PYTHON SOURCE LINES 115-121

.. code-block:: default

    study = optuna.create_study(directions=["minimize", "maximize"])
    study.optimize(objective, n_trials=30, timeout=300)

    print("Number of finished trials: ", len(study.trials))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../FashionMNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0/26421880 [00:00<?, ?it/s]      0%|          | 13312/26421880 [00:00<03:51, 114004.18it/s]      0%|          | 43008/26421880 [00:00<02:15, 195344.11it/s]      0%|          | 103424/26421880 [00:00<01:17, 340012.51it/s]      1%|          | 211968/26421880 [00:00<00:46, 568432.55it/s]      2%|1         | 441344/26421880 [00:00<00:24, 1063273.48it/s]      3%|3         | 899072/26421880 [00:00<00:12, 2016253.37it/s]      7%|6         | 1815552/26421880 [00:00<00:06, 3888400.26it/s]     14%|#3        | 3648512/26421880 [00:00<00:03, 7577733.05it/s]     24%|##4       | 6385664/26421880 [00:01<00:01, 12445000.73it/s]     34%|###4      | 9069568/26421880 [00:01<00:01, 15614107.15it/s]     46%|####6     | 12211200/26421880 [00:01<00:00, 18973599.67it/s]     58%|#####7    | 15320064/26421880 [00:01<00:00, 21187726.88it/s]     69%|######8   | 18122752/26421880 [00:01<00:00, 21848593.95it/s]     80%|#######9  | 21093376/26421880 [00:01<00:00, 22835716.58it/s]     91%|#########1| 24096768/26421880 [00:01<00:00, 23576054.49it/s]    26422272it [00:01, 14678280.20it/s]                              
    Extracting ../FashionMNIST/raw/train-images-idx3-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0/29515 [00:00<?, ?it/s]     45%|####5     | 13312/29515 [00:00<00:00, 109686.67it/s]    29696it [00:00, 243209.30it/s]                           
    Extracting ../FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0/4422102 [00:00<?, ?it/s]      0%|          | 14336/4422102 [00:00<00:37, 116505.74it/s]      1%|1         | 45056/4422102 [00:00<00:22, 193941.42it/s]      2%|2         | 104448/4422102 [00:00<00:13, 324544.15it/s]      5%|5         | 225280/4422102 [00:00<00:07, 580428.37it/s]     11%|#         | 465920/4422102 [00:00<00:03, 1070154.11it/s]     21%|##1       | 947200/4422102 [00:00<00:01, 2026590.42it/s]     43%|####3     | 1908736/4422102 [00:00<00:00, 3899269.02it/s]     87%|########6 | 3833856/4422102 [00:00<00:00, 7556762.52it/s]    4422656it [00:00, 4429495.13it/s]                             
    Extracting ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0/5148 [00:00<?, ?it/s]    6144it [00:00, 25590669.09it/s]         
    Extracting ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw

    Number of finished trials:  30




.. GENERATED FROM PYTHON SOURCE LINES 122-123

Check trials on Pareto front visually.

.. GENERATED FROM PYTHON SOURCE LINES 123-126

.. code-block:: default

    optuna.visualization.plot_pareto_front(study, target_names=["FLOPS", "accuracy"])







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.14.0.min.js"></script>                <div id="db1794a7-2b55-4eeb-ab68-51802f1f080b" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("db1794a7-2b55-4eeb-ab68-51802f1f080b")) {                    Plotly.newPlot(                        "db1794a7-2b55-4eeb-ab68-51802f1f080b",                        [{"hovertemplate":"%{text}<extra>Trial</extra>","marker":{"color":[0,1,3,4,5,6,7,8,10,11,12,14,15,16,17,18,21,22,23,24,25,26,28,29],"colorbar":{"title":{"text":"Trial"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 0,<br>  \"values\": [<br>    90516.0,<br>    0.70703125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 114,<br>    \"dropout_0\": 0.2868976620819571,<br>    \"lr\": 0.053507997429625996<br>  }<br>}","{<br>  \"number\": 1,<br>  \"values\": [<br>    87927.0,<br>    0.7015625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 102,<br>    \"dropout_0\": 0.2568145414299322,<br>    \"n_units_l1\": 31,<br>    \"dropout_1\": 0.48568103857226413,<br>    \"n_units_l2\": 117,<br>    \"dropout_2\": 0.2332865648511368,<br>    \"lr\": 0.000368540568912081<br>  }<br>}","{<br>  \"number\": 3,<br>  \"values\": [<br>    45258.0,<br>    0.66875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 57,<br>    \"dropout_0\": 0.39332375083986026,<br>    \"lr\": 0.00010879115323240186<br>  }<br>}","{<br>  \"number\": 4,<br>  \"values\": [<br>    37978.0,<br>    0.43984375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 47,<br>    \"dropout_0\": 0.24733738292618188,<br>    \"n_units_l1\": 6,<br>    \"dropout_1\": 0.2870334598886408,<br>    \"n_units_l2\": 53,<br>    \"dropout_2\": 0.26411707050667643,<br>    \"lr\": 0.00010602539153291109<br>  }<br>}","{<br>  \"number\": 5,<br>  \"values\": [<br>    73130.0,<br>    0.09296875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 80,<br>    \"dropout_0\": 0.30164618506696517,<br>    \"n_units_l1\": 108,<br>    \"dropout_1\": 0.349122276180045,<br>    \"n_units_l2\": 15,<br>    \"dropout_2\": 0.3991112640332328,<br>    \"lr\": 0.08847924799582142<br>  }<br>}","{<br>  \"number\": 6,<br>  \"values\": [<br>    73842.0,<br>    0.8125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 93,<br>    \"dropout_0\": 0.4825928866887383,<br>    \"lr\": 0.0007229636641329162<br>  }<br>}","{<br>  \"number\": 7,<br>  \"values\": [<br>    94041.0,<br>    0.50546875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 119,<br>    \"dropout_0\": 0.3783868521951017,<br>    \"n_units_l1\": 5,<br>    \"dropout_1\": 0.4038739833436312,<br>    \"n_units_l2\": 10,<br>    \"dropout_2\": 0.4953126514777425,<br>    \"lr\": 0.001380074422775748<br>  }<br>}","{<br>  \"number\": 8,<br>  \"values\": [<br>    62726.0,<br>    0.459375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 79,<br>    \"dropout_0\": 0.4954909316726366,<br>    \"lr\": 1.2354466223053367e-05<br>  }<br>}","{<br>  \"number\": 10,<br>  \"values\": [<br>    81532.0,<br>    0.80546875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 90,<br>    \"dropout_0\": 0.3605463153740993,<br>    \"n_units_l1\": 46,<br>    \"dropout_1\": 0.3545343166974624,<br>    \"n_units_l2\": 122,<br>    \"dropout_2\": 0.3182488176152383,<br>    \"lr\": 0.00449402071324496<br>  }<br>}","{<br>  \"number\": 11,<br>  \"values\": [<br>    69872.0,<br>    0.41328125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 88,<br>    \"dropout_0\": 0.4919383353740476,<br>    \"lr\": 0.0706911763801027<br>  }<br>}","{<br>  \"number\": 12,<br>  \"values\": [<br>    104098.0,<br>    0.2875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 127,<br>    \"dropout_0\": 0.32668733658427385,<br>    \"n_units_l1\": 15,<br>    \"dropout_1\": 0.30359460264314425,<br>    \"n_units_l2\": 105,<br>    \"dropout_2\": 0.3520944517353834,<br>    \"lr\": 3.593692305533183e-05<br>  }<br>}","{<br>  \"number\": 14,<br>  \"values\": [<br>    38565.0,<br>    0.4484375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 39,<br>    \"dropout_0\": 0.3867620489313942,<br>    \"n_units_l1\": 47,<br>    \"dropout_1\": 0.3570363426865792,<br>    \"n_units_l2\": 108,<br>    \"dropout_2\": 0.3132764329320389,<br>    \"lr\": 0.04632488006750845<br>  }<br>}","{<br>  \"number\": 15,<br>  \"values\": [<br>    70035.0,<br>    0.8171875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 79,<br>    \"dropout_0\": 0.2047193518054403,<br>    \"n_units_l1\": 91,<br>    \"dropout_1\": 0.21775188129153064,<br>    \"lr\": 0.004842604972324002<br>  }<br>}","{<br>  \"number\": 16,<br>  \"values\": [<br>    19056.0,<br>    0.378125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 24,<br>    \"dropout_0\": 0.33772496823568166,<br>    \"lr\": 3.2023223943364966e-05<br>  }<br>}","{<br>  \"number\": 17,<br>  \"values\": [<br>    41698.0,<br>    0.65390625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 52,<br>    \"dropout_0\": 0.24007214312117206,<br>    \"n_units_l1\": 15,<br>    \"dropout_1\": 0.2921845836837499,<br>    \"lr\": 0.00023557279546441146<br>  }<br>}","{<br>  \"number\": 18,<br>  \"values\": [<br>    33863.0,<br>    0.1015625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 37,<br>    \"dropout_0\": 0.262897586254928,<br>    \"n_units_l1\": 45,<br>    \"dropout_1\": 0.46347342362028704,<br>    \"n_units_l2\": 58,<br>    \"dropout_2\": 0.3788672313606114,<br>    \"lr\": 0.09049410486380531<br>  }<br>}","{<br>  \"number\": 21,<br>  \"values\": [<br>    61932.0,<br>    0.575<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 78,<br>    \"dropout_0\": 0.36715785383524757,<br>    \"lr\": 1.868566126559276e-05<br>  }<br>}","{<br>  \"number\": 22,<br>  \"values\": [<br>    42876.0,<br>    0.653125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 54,<br>    \"dropout_0\": 0.23559316599885857,<br>    \"lr\": 6.653763294608021e-05<br>  }<br>}","{<br>  \"number\": 23,<br>  \"values\": [<br>    32554.0,<br>    0.603125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 41,<br>    \"dropout_0\": 0.36405964650181966,<br>    \"lr\": 3.5022952915957836e-05<br>  }<br>}","{<br>  \"number\": 24,<br>  \"values\": [<br>    47640.0,<br>    0.5390625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 60,<br>    \"dropout_0\": 0.30967734090064003,<br>    \"lr\": 0.07665125961837913<br>  }<br>}","{<br>  \"number\": 25,<br>  \"values\": [<br>    57680.0,<br>    0.72109375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 62,<br>    \"dropout_0\": 0.346433038176095,<br>    \"n_units_l1\": 126,<br>    \"dropout_1\": 0.20860258835465267,<br>    \"lr\": 0.000235503884998206<br>  }<br>}","{<br>  \"number\": 26,<br>  \"values\": [<br>    113200.0,<br>    0.6375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 126,<br>    \"dropout_0\": 0.3505100122960344,<br>    \"n_units_l1\": 106,<br>    \"dropout_1\": 0.28355165136335997,<br>    \"lr\": 7.159102457135023e-05<br>  }<br>}","{<br>  \"number\": 28,<br>  \"values\": [<br>    98652.0,<br>    0.7078125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 123,<br>    \"dropout_0\": 0.3962829464141304,<br>    \"n_units_l1\": 15,<br>    \"dropout_1\": 0.3296642258701719,<br>    \"n_units_l2\": 15,<br>    \"dropout_2\": 0.3621994265579219,<br>    \"lr\": 0.0023955796976977283<br>  }<br>}","{<br>  \"number\": 29,<br>  \"values\": [<br>    49263.0,<br>    0.40078125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 59,<br>    \"dropout_0\": 0.351583763406846,<br>    \"n_units_l1\": 23,<br>    \"dropout_1\": 0.28071562317142645,<br>    \"n_units_l2\": 50,<br>    \"dropout_2\": 0.3345389379251552,<br>    \"lr\": 4.6519496240481866e-05<br>  }<br>}"],"x":[90516.0,87927.0,45258.0,37978.0,73130.0,73842.0,94041.0,62726.0,81532.0,69872.0,104098.0,38565.0,70035.0,19056.0,41698.0,33863.0,61932.0,42876.0,32554.0,47640.0,57680.0,113200.0,98652.0,49263.0],"y":[0.70703125,0.7015625,0.66875,0.43984375,0.09296875,0.8125,0.50546875,0.459375,0.80546875,0.41328125,0.2875,0.4484375,0.8171875,0.378125,0.65390625,0.1015625,0.575,0.653125,0.603125,0.5390625,0.72109375,0.6375,0.7078125,0.40078125],"type":"scatter"},{"hovertemplate":"%{text}<extra>Best Trial</extra>","marker":{"color":[2,9,13,19,20,27],"colorbar":{"title":{"text":"Best Trial"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 2,<br>  \"values\": [<br>    67490.0,<br>    0.82265625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 85,<br>    \"dropout_0\": 0.4359019623179654,<br>    \"lr\": 0.009826952903842959<br>  }<br>}","{<br>  \"number\": 9,<br>  \"values\": [<br>    32379.0,<br>    0.7234375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 35,<br>    \"dropout_0\": 0.42954365720731236,<br>    \"n_units_l1\": 119,<br>    \"dropout_1\": 0.32263157000662707,<br>    \"n_units_l2\": 6,<br>    \"dropout_2\": 0.20527370328884578,<br>    \"lr\": 0.006806553658929738<br>  }<br>}","{<br>  \"number\": 13,<br>  \"values\": [<br>    11712.0,<br>    0.39921875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 8,<br>    \"dropout_0\": 0.4878406213132582,<br>    \"n_units_l1\": 128,<br>    \"dropout_1\": 0.3894084455090817,<br>    \"n_units_l2\": 32,<br>    \"dropout_2\": 0.36113791874290124,<br>    \"lr\": 0.004355874841806721<br>  }<br>}","{<br>  \"number\": 19,<br>  \"values\": [<br>    42555.0,<br>    0.76796875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 51,<br>    \"dropout_0\": 0.3532256658346855,<br>    \"n_units_l1\": 29,<br>    \"dropout_1\": 0.2336007972668615,<br>    \"n_units_l2\": 28,<br>    \"dropout_2\": 0.20843407291216332,<br>    \"lr\": 0.001685694030695456<br>  }<br>}","{<br>  \"number\": 20,<br>  \"values\": [<br>    26464.0,<br>    0.6828125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 23,<br>    \"dropout_0\": 0.42210600065843495,<br>    \"n_units_l1\": 112,<br>    \"dropout_1\": 0.2009907837163809,<br>    \"n_units_l2\": 48,<br>    \"dropout_2\": 0.36531366379514274,<br>    \"lr\": 0.00035464713155960916<br>  }<br>}","{<br>  \"number\": 27,<br>  \"values\": [<br>    89948.0,<br>    0.82421875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 106,<br>    \"dropout_0\": 0.34806334020946206,<br>    \"n_units_l1\": 59,<br>    \"dropout_1\": 0.4828012083789414,<br>    \"lr\": 0.0018296853727591826<br>  }<br>}"],"x":[67490.0,32379.0,11712.0,42555.0,26464.0,89948.0],"y":[0.82265625,0.7234375,0.39921875,0.76796875,0.6828125,0.82421875],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 127-130

Fetch the list of trials on the Pareto front with :attr:`~optuna.study.Study.best_trials`.

For example, the following code shows the number of trials on the Pareto front and picks the trial with the highest accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 130-139

.. code-block:: default


    print(f"Number of trials on the Pareto front: {len(study.best_trials)}")

    trial_with_highest_accuracy = max(study.best_trials, key=lambda t: t.values[1])
    print(f"Trial with highest accuracy: ")
    print(f"\tnumber: {trial_with_highest_accuracy.number}")
    print(f"\tparams: {trial_with_highest_accuracy.params}")
    print(f"\tvalues: {trial_with_highest_accuracy.values}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Number of trials on the Pareto front: 6
    Trial with highest accuracy: 
            number: 27
            params: {'n_layers': 2, 'n_units_l0': 106, 'dropout_0': 0.34806334020946206, 'n_units_l1': 59, 'dropout_1': 0.4828012083789414, 'lr': 0.0018296853727591826}
            values: [89948.0, 0.82421875]




.. GENERATED FROM PYTHON SOURCE LINES 140-141

Learn which hyperparameters are affecting the flops most with hyperparameter importance.

.. GENERATED FROM PYTHON SOURCE LINES 141-144

.. code-block:: default

    optuna.visualization.plot_param_importances(
        study, target=lambda t: t.values[0], target_name="flops"
    )





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.14.0.min.js"></script>                <div id="6868280a-4b65-4805-9df7-e403d56690ce" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("6868280a-4b65-4805-9df7-e403d56690ce")) {                    Plotly.newPlot(                        "6868280a-4b65-4805-9df7-e403d56690ce",                        [{"cliponaxis":false,"hovertemplate":["n_layers (IntDistribution): 0.0009885937790998173<extra></extra>","lr (FloatDistribution): 0.0009948579007128195<extra></extra>","dropout_0 (FloatDistribution): 0.00595927819900542<extra></extra>","n_units_l0 (IntDistribution): 0.9920572701211819<extra></extra>"],"marker":{"color":"rgb(66,146,198)"},"orientation":"h","text":["<0.01","<0.01","<0.01","0.99"],"textposition":"outside","x":[0.0009885937790998173,0.0009948579007128195,0.00595927819900542,0.9920572701211819],"y":["n_layers","lr","dropout_0","n_units_l0"],"type":"bar"}],                        {"showlegend":false,"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Importance for flops"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  18.712 seconds)


.. _sphx_glr_download_tutorial_20_recipes_002_multi_objective.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 002_multi_objective.py <002_multi_objective.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 002_multi_objective.ipynb <002_multi_objective.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
